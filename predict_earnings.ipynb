{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ff10f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wrds in c:\\users\\abbas\\anaconda3\\lib\\site-packages (3.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\abbas\\anaconda3\\lib\\site-packages (from wrds) (1.23.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\abbas\\anaconda3\\lib\\site-packages (from wrds) (1.4.4)\n",
      "Requirement already satisfied: sqlalchemy<2 in c:\\users\\abbas\\anaconda3\\lib\\site-packages (from wrds) (1.4.39)\n",
      "Requirement already satisfied: psycopg2-binary in c:\\users\\abbas\\anaconda3\\lib\\site-packages (from wrds) (2.9.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\abbas\\anaconda3\\lib\\site-packages (from wrds) (1.9.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\abbas\\anaconda3\\lib\\site-packages (from sqlalchemy<2->wrds) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\abbas\\anaconda3\\lib\\site-packages (from pandas->wrds) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abbas\\anaconda3\\lib\\site-packages (from pandas->wrds) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abbas\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->wrds) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wrds\n",
    "import wrds\n",
    "import pandas as pd\n",
    "from scipy.stats.mstats import winsorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c0d345f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "db = wrds.Connection(wrds_username= 'clkride')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc8737d",
   "metadata": {},
   "source": [
    "# Step 1: Download All Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014b23ab",
   "metadata": {},
   "source": [
    "#### Import Compustat Dataset from WRDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59053e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the compustat dataset\n",
    "library = 'comp'\n",
    "file = 'funda'\n",
    "\n",
    "# set the required filters\n",
    "indfmt = 'INDL'\n",
    "datafmt = 'STD'\n",
    "popsrc = 'D'\n",
    "consol = 'C'\n",
    "\n",
    "# fyear = 2009 to 2023\n",
    "# set up query\n",
    "query = f\"SELECT * FROM {library}.{file} WHERE indfmt='{indfmt}' AND datafmt='{datafmt}' AND popsrc='{popsrc}' AND consol='{consol}' AND datadate >= '01/01/2009' AND datadate <='12/31/2023'\"\n",
    "# execute query\n",
    "comp_data = db.raw_sql(query) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82e8c95",
   "metadata": {},
   "source": [
    "To extract Indusrty Code, merge with company table and get the sic code, then extract first two digits of sic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b506eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in company data\n",
    "company_data = db.get_table(library='comp', table='company', columns=['gvkey', 'sic'])\n",
    "\n",
    "# Merge the two dataframes\n",
    "merged_data = comp_data.merge(company_data, on='gvkey', how='left')\n",
    "\n",
    "# convert the 'sic' column from strings to integers\n",
    "merged_data['sic'] = merged_data['sic'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9646ec0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\249207560.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_data['industry'] = merged_data['sic'].astype(str).str[:2].astype(int)\n"
     ]
    }
   ],
   "source": [
    "# extract the first two digits of sic column and store them in a new column\n",
    "merged_data['industry'] = merged_data['sic'].astype(str).str[:2].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afb4dd5",
   "metadata": {},
   "source": [
    "For lean operation, perform garbage collection to free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a53f066d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del company_data\n",
    "# Perform garbage collection\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c47ca25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter all required columns\n",
    "df = merged_data[['gvkey','tic','conm','invch','sic','prcc_f','fyear','cusip', 'industry','ib', 'spi', 'at', 'dvc', 'act', 'che', 'lct', 'dlc', 'txp', 'dp', 'csho', 'ceq', 'ivao', 'lt', 'dltt', 'ivst', 'pstk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b257a6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\4236409823.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[['spi', 'dvc', 'che', 'lct', 'dlc', 'txp', 'dp', 'ceq', 'ivao', 'lt', 'dltt', 'ivst', 'pstk']] = df[['spi', 'dvc', 'che', 'lct', 'dlc', 'txp', 'dp', 'ceq', 'ivao', 'lt', 'dltt', 'ivst', 'pstk']].fillna(0)\n"
     ]
    }
   ],
   "source": [
    "# replace missing values with zeros for the specified columns\n",
    "df[['spi', 'dvc', 'che', 'lct', 'dlc', 'txp', 'dp', 'ceq', 'ivao', 'lt', 'dltt', 'ivst', 'pstk']] = df[['spi', 'dvc', 'che', 'lct', 'dlc', 'txp', 'dp', 'ceq', 'ivao', 'lt', 'dltt', 'ivst', 'pstk']].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076b1759",
   "metadata": {},
   "source": [
    "#### Import IBES Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e277ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "library = 'ibes'\n",
    "file = 'statsum_epsus'\n",
    "\n",
    "# set the required filters\n",
    "FPI = 1\n",
    "Measure = 'EPS'\n",
    "\n",
    "# set up query\n",
    "query_ibes = f\"SELECT * FROM {library}.{file} WHERE FPI='{FPI}' AND Measure='{Measure}' AND fpedats BETWEEN '2010-01-01' AND '2022-12-31'\"\n",
    "# execute query\n",
    "ibes_data = db.raw_sql(query_ibes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f279928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>cusip</th>\n",
       "      <th>oftic</th>\n",
       "      <th>cname</th>\n",
       "      <th>statpers</th>\n",
       "      <th>measure</th>\n",
       "      <th>fiscalp</th>\n",
       "      <th>fpi</th>\n",
       "      <th>estflag</th>\n",
       "      <th>curcode</th>\n",
       "      <th>...</th>\n",
       "      <th>highest</th>\n",
       "      <th>lowest</th>\n",
       "      <th>usfirm</th>\n",
       "      <th>fpedats</th>\n",
       "      <th>actual</th>\n",
       "      <th>actdats_act</th>\n",
       "      <th>acttims_act</th>\n",
       "      <th>anndats_act</th>\n",
       "      <th>anntims_act</th>\n",
       "      <th>curr_act</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000</td>\n",
       "      <td>87482X10</td>\n",
       "      <td>TLMR</td>\n",
       "      <td>TALMER BANCORP</td>\n",
       "      <td>2014-04-17</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>1.21</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>60887.0</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>59400.0</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000</td>\n",
       "      <td>87482X10</td>\n",
       "      <td>TLMR</td>\n",
       "      <td>TALMER BANCORP</td>\n",
       "      <td>2014-05-15</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>1.21</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>60887.0</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>59400.0</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000</td>\n",
       "      <td>87482X10</td>\n",
       "      <td>TLMR</td>\n",
       "      <td>TALMER BANCORP</td>\n",
       "      <td>2014-06-19</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>1.21</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>60887.0</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>59400.0</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000</td>\n",
       "      <td>87482X10</td>\n",
       "      <td>TLMR</td>\n",
       "      <td>TALMER BANCORP</td>\n",
       "      <td>2014-07-17</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>1.21</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>60887.0</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>59400.0</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000</td>\n",
       "      <td>87482X10</td>\n",
       "      <td>TLMR</td>\n",
       "      <td>TALMER BANCORP</td>\n",
       "      <td>2014-08-14</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>1.21</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>60887.0</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>59400.0</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker     cusip oftic           cname    statpers measure fiscalp fpi  \\\n",
       "0   0000  87482X10  TLMR  TALMER BANCORP  2014-04-17     EPS     ANN   1   \n",
       "1   0000  87482X10  TLMR  TALMER BANCORP  2014-05-15     EPS     ANN   1   \n",
       "2   0000  87482X10  TLMR  TALMER BANCORP  2014-06-19     EPS     ANN   1   \n",
       "3   0000  87482X10  TLMR  TALMER BANCORP  2014-07-17     EPS     ANN   1   \n",
       "4   0000  87482X10  TLMR  TALMER BANCORP  2014-08-14     EPS     ANN   1   \n",
       "\n",
       "  estflag curcode  ...  highest  lowest  usfirm     fpedats  actual  \\\n",
       "0       P     USD  ...     0.56    0.50     1.0  2014-12-31    1.21   \n",
       "1       P     USD  ...     0.58    0.50     1.0  2014-12-31    1.21   \n",
       "2       P     USD  ...     0.59    0.50     1.0  2014-12-31    1.21   \n",
       "3       P     USD  ...     0.59    0.50     1.0  2014-12-31    1.21   \n",
       "4       P     USD  ...     1.24    1.09     1.0  2014-12-31    1.21   \n",
       "\n",
       "   actdats_act  acttims_act  anndats_act  anntims_act curr_act  \n",
       "0   2015-01-30      60887.0   2015-01-30      59400.0      USD  \n",
       "1   2015-01-30      60887.0   2015-01-30      59400.0      USD  \n",
       "2   2015-01-30      60887.0   2015-01-30      59400.0      USD  \n",
       "3   2015-01-30      60887.0   2015-01-30      59400.0      USD  \n",
       "4   2015-01-30      60887.0   2015-01-30      59400.0      USD  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibes_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b755eb8",
   "metadata": {},
   "source": [
    "#### Import comp_na_daily for cshom and prccm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7285ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in company data\n",
    "#monthly_data = db.raw_sql(\"\"\" select prccm, tic, cshom, datadate from comp_na_daily_all.secm where cyear >= 2010\"\"\")\n",
    "\n",
    "#monthly_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc2bb0c",
   "metadata": {},
   "source": [
    "Extract only rows from month of June"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfcbd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#monthly_data['datadate'] = pd.to_datetime(monthly_data['datadate'])\n",
    "#monthly_data = monthly_data[(monthly_data['datadate'].dt.month == 6)]\n",
    "#monthly_data['fyear'] = monthly_data['datadate'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7fe821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the 'city' column\n",
    "#monthly_data = monthly_data.drop('datadate', axis=1)\n",
    "#monthly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f5ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge compustat dataset with monthly data to include cshom values\n",
    "#monthly_data = df.merge(monthly_data, on=['tic','fyear'], how='left')\n",
    "#monthly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffaf1d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>tic</th>\n",
       "      <th>conm</th>\n",
       "      <th>invch</th>\n",
       "      <th>sic</th>\n",
       "      <th>prcc_f</th>\n",
       "      <th>fyear</th>\n",
       "      <th>cusip</th>\n",
       "      <th>industry</th>\n",
       "      <th>ib</th>\n",
       "      <th>...</th>\n",
       "      <th>dlc</th>\n",
       "      <th>txp</th>\n",
       "      <th>dp</th>\n",
       "      <th>csho</th>\n",
       "      <th>ceq</th>\n",
       "      <th>ivao</th>\n",
       "      <th>lt</th>\n",
       "      <th>dltt</th>\n",
       "      <th>ivst</th>\n",
       "      <th>pstk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001004</td>\n",
       "      <td>AIR</td>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>-34.615</td>\n",
       "      <td>5080</td>\n",
       "      <td>26.3900</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>000361105</td>\n",
       "      <td>50</td>\n",
       "      <td>73.139</td>\n",
       "      <td>...</td>\n",
       "      <td>114.075</td>\n",
       "      <td>0.000</td>\n",
       "      <td>59.296</td>\n",
       "      <td>39.781</td>\n",
       "      <td>835.845</td>\n",
       "      <td>2.443</td>\n",
       "      <td>868.438</td>\n",
       "      <td>329.802</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001004</td>\n",
       "      <td>AIR</td>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>-42.057</td>\n",
       "      <td>5080</td>\n",
       "      <td>12.0500</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>000361105</td>\n",
       "      <td>50</td>\n",
       "      <td>67.723</td>\n",
       "      <td>...</td>\n",
       "      <td>122.865</td>\n",
       "      <td>0.000</td>\n",
       "      <td>80.333</td>\n",
       "      <td>40.273</td>\n",
       "      <td>864.649</td>\n",
       "      <td>18.869</td>\n",
       "      <td>1329.631</td>\n",
       "      <td>669.489</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001004</td>\n",
       "      <td>AIR</td>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>26.500</td>\n",
       "      <td>5080</td>\n",
       "      <td>20.0600</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>000361105</td>\n",
       "      <td>50</td>\n",
       "      <td>55.000</td>\n",
       "      <td>...</td>\n",
       "      <td>86.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>108.600</td>\n",
       "      <td>39.382</td>\n",
       "      <td>918.600</td>\n",
       "      <td>16.800</td>\n",
       "      <td>1217.400</td>\n",
       "      <td>622.200</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001004</td>\n",
       "      <td>AIR</td>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>-36.600</td>\n",
       "      <td>5080</td>\n",
       "      <td>24.3000</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>000361105</td>\n",
       "      <td>50</td>\n",
       "      <td>72.900</td>\n",
       "      <td>...</td>\n",
       "      <td>69.700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>113.400</td>\n",
       "      <td>39.560</td>\n",
       "      <td>999.500</td>\n",
       "      <td>5.200</td>\n",
       "      <td>1198.800</td>\n",
       "      <td>564.300</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>001004</td>\n",
       "      <td>AIR</td>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>-36.600</td>\n",
       "      <td>5080</td>\n",
       "      <td>29.5400</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>000361105</td>\n",
       "      <td>50</td>\n",
       "      <td>-54.500</td>\n",
       "      <td>...</td>\n",
       "      <td>69.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>92.300</td>\n",
       "      <td>35.423</td>\n",
       "      <td>845.100</td>\n",
       "      <td>4.300</td>\n",
       "      <td>669.900</td>\n",
       "      <td>85.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160393</th>\n",
       "      <td>351038</td>\n",
       "      <td>QNRX</td>\n",
       "      <td>CELLECT BIOTECHNOLOGY LTD</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2834</td>\n",
       "      <td>1.4200</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>74907L201</td>\n",
       "      <td>28</td>\n",
       "      <td>-9.381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.104</td>\n",
       "      <td>4.847</td>\n",
       "      <td>7.407</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.051</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9.993</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160397</th>\n",
       "      <td>351491</td>\n",
       "      <td>IVCGF</td>\n",
       "      <td>IVECO GROUP N V</td>\n",
       "      <td>-234.055</td>\n",
       "      <td>3711</td>\n",
       "      <td>5.8800</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>N47017103</td>\n",
       "      <td>37</td>\n",
       "      <td>157.105</td>\n",
       "      <td>...</td>\n",
       "      <td>3786.553</td>\n",
       "      <td>114.355</td>\n",
       "      <td>828.275</td>\n",
       "      <td>271.215</td>\n",
       "      <td>2514.750</td>\n",
       "      <td>167.792</td>\n",
       "      <td>14558.406</td>\n",
       "      <td>951.181</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160400</th>\n",
       "      <td>351590</td>\n",
       "      <td>DTRUY</td>\n",
       "      <td>DAIMLER TRUCK HOLDING AG</td>\n",
       "      <td>-1486.484</td>\n",
       "      <td>3713</td>\n",
       "      <td>18.4389</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>23384L101</td>\n",
       "      <td>37</td>\n",
       "      <td>2669.303</td>\n",
       "      <td>...</td>\n",
       "      <td>6231.408</td>\n",
       "      <td>276.370</td>\n",
       "      <td>2035.813</td>\n",
       "      <td>1645.904</td>\n",
       "      <td>18106.225</td>\n",
       "      <td>10910.365</td>\n",
       "      <td>43647.149</td>\n",
       "      <td>12647.062</td>\n",
       "      <td>119.419</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160401</th>\n",
       "      <td>351590</td>\n",
       "      <td>DTRUY</td>\n",
       "      <td>DAIMLER TRUCK HOLDING AG</td>\n",
       "      <td>-1221.573</td>\n",
       "      <td>3713</td>\n",
       "      <td>15.4460</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>23384L101</td>\n",
       "      <td>37</td>\n",
       "      <td>2848.198</td>\n",
       "      <td>...</td>\n",
       "      <td>8027.323</td>\n",
       "      <td>184.892</td>\n",
       "      <td>1963.278</td>\n",
       "      <td>1645.904</td>\n",
       "      <td>21430.419</td>\n",
       "      <td>13970.599</td>\n",
       "      <td>46343.870</td>\n",
       "      <td>14244.198</td>\n",
       "      <td>1201.266</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160403</th>\n",
       "      <td>353444</td>\n",
       "      <td>HLN</td>\n",
       "      <td>HALEON PLC</td>\n",
       "      <td>-351.831</td>\n",
       "      <td>2834</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>405552100</td>\n",
       "      <td>28</td>\n",
       "      <td>1277.194</td>\n",
       "      <td>...</td>\n",
       "      <td>526.542</td>\n",
       "      <td>253.029</td>\n",
       "      <td>345.806</td>\n",
       "      <td>4617.287</td>\n",
       "      <td>19677.222</td>\n",
       "      <td>159.047</td>\n",
       "      <td>22119.555</td>\n",
       "      <td>12052.615</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73164 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         gvkey    tic                       conm     invch   sic   prcc_f  \\\n",
       "2       001004    AIR                   AAR CORP   -34.615  5080  26.3900   \n",
       "3       001004    AIR                   AAR CORP   -42.057  5080  12.0500   \n",
       "4       001004    AIR                   AAR CORP    26.500  5080  20.0600   \n",
       "5       001004    AIR                   AAR CORP   -36.600  5080  24.3000   \n",
       "6       001004    AIR                   AAR CORP   -36.600  5080  29.5400   \n",
       "...        ...    ...                        ...       ...   ...      ...   \n",
       "160393  351038   QNRX  CELLECT BIOTECHNOLOGY LTD     0.000  2834   1.4200   \n",
       "160397  351491  IVCGF            IVECO GROUP N V  -234.055  3711   5.8800   \n",
       "160400  351590  DTRUY   DAIMLER TRUCK HOLDING AG -1486.484  3713  18.4389   \n",
       "160401  351590  DTRUY   DAIMLER TRUCK HOLDING AG -1221.573  3713  15.4460   \n",
       "160403  353444    HLN                 HALEON PLC  -351.831  2834   8.0000   \n",
       "\n",
       "         fyear      cusip  industry        ib  ...       dlc      txp  \\\n",
       "2       2010.0  000361105        50    73.139  ...   114.075    0.000   \n",
       "3       2011.0  000361105        50    67.723  ...   122.865    0.000   \n",
       "4       2012.0  000361105        50    55.000  ...    86.400    0.000   \n",
       "5       2013.0  000361105        50    72.900  ...    69.700    0.000   \n",
       "6       2014.0  000361105        50   -54.500  ...    69.000    0.000   \n",
       "...        ...        ...       ...       ...  ...       ...      ...   \n",
       "160393  2022.0  74907L201        28    -9.381  ...     0.000    0.000   \n",
       "160397  2022.0  N47017103        37   157.105  ...  3786.553  114.355   \n",
       "160400  2021.0  23384L101        37  2669.303  ...  6231.408  276.370   \n",
       "160401  2022.0  23384L101        37  2848.198  ...  8027.323  184.892   \n",
       "160403  2022.0  405552100        28  1277.194  ...   526.542  253.029   \n",
       "\n",
       "              dp      csho        ceq       ivao         lt       dltt  \\\n",
       "2         59.296    39.781    835.845      2.443    868.438    329.802   \n",
       "3         80.333    40.273    864.649     18.869   1329.631    669.489   \n",
       "4        108.600    39.382    918.600     16.800   1217.400    622.200   \n",
       "5        113.400    39.560    999.500      5.200   1198.800    564.300   \n",
       "6         92.300    35.423    845.100      4.300    669.900     85.000   \n",
       "...          ...       ...        ...        ...        ...        ...   \n",
       "160393     0.104     4.847      7.407      0.000      7.051      0.000   \n",
       "160397   828.275   271.215   2514.750    167.792  14558.406    951.181   \n",
       "160400  2035.813  1645.904  18106.225  10910.365  43647.149  12647.062   \n",
       "160401  1963.278  1645.904  21430.419  13970.599  46343.870  14244.198   \n",
       "160403   345.806  4617.287  19677.222    159.047  22119.555  12052.615   \n",
       "\n",
       "            ivst   pstk  \n",
       "2          0.000  0.000  \n",
       "3          0.000  0.000  \n",
       "4          0.000  0.000  \n",
       "5          0.000  0.000  \n",
       "6          0.000  0.000  \n",
       "...          ...    ...  \n",
       "160393     9.993  0.000  \n",
       "160397     0.000  1.069  \n",
       "160400   119.419  0.000  \n",
       "160401  1201.266  0.000  \n",
       "160403     0.000  0.000  \n",
       "\n",
       "[73164 rows x 26 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a boolean mask to filter rows where fyear is less than 2010\n",
    "mask = df['fyear'] > 2009\n",
    "\n",
    "# use the boolean mask to filter the dataframe and drop the rows where fyear is less than 2010\n",
    "df = df[mask].dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17769d9",
   "metadata": {},
   "source": [
    "#### Function to calculate all the X variables and Y variable values for HVZ, EP and RI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4c1ce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to calculate delta values within each group\n",
    "def calc_deltas(group):\n",
    "   # Calculate changes in variables\n",
    "     group['del_STDebt'] = group['dlc'] - group['dlc'].shift(1) # sign is positive\n",
    "     group['del_CA'] = group['act'] - group['act'].shift(1) # sign is positive\n",
    "     group['del_CL'] = group['lct'] - group['lct'].shift(1) # sign is negative\n",
    "     group['del_Cash'] = group['che'] - group['che'].shift(1) # sign negative\n",
    "     group['del_txp'] = group['txp'] - group['txp'].shift(1) # sign positive\n",
    "\n",
    "   # Calculate total current accruals using the equation\n",
    "     group['ACT'] = group['del_CA'] - group['del_Cash'] - group['del_CL']+ group['del_STDebt'] + group['del_txp'] - group['dp']\n",
    "     \n",
    "  # y-variable for HVZ\n",
    "     group['E_t'] = group['ib']-group['spi']\n",
    "     group['E_t1_HVZ']= group['ib'].shift(-1)-group['spi'].shift(-1)\n",
    "     group['E_t2_HVZ']= group['ib'].shift(-2)-group['spi'].shift(-2)\n",
    "     group['E_t3_HVZ']= group['ib'].shift(-3)-group['spi'].shift(-3)\n",
    "\n",
    "  # Variables for EP and Model\n",
    "     # add small number to avoid division by zero\n",
    "     group['EPS'] = group['E_t']/(group['csho']+ 1e-6)\n",
    "     group['E_t1_EP_RI']= (group['ib'].shift(-1)-group['spi'].shift(-1))/(group['csho']+ 1e-6)\n",
    "     group['E_t2_EP_RI']= (group['ib'].shift(-2)-group['spi'].shift(-2))/(group['csho']+ 1e-6)\n",
    "     group['E_t3_EP_RI']= (group['ib'].shift(-3)-group['spi'].shift(-3))/(group['csho']+ 1e-6)\n",
    "\n",
    "  # Variables for RI Model\n",
    "     group['B_t'] = group['ceq']/group['csho']  # Book value \n",
    "     group['WC'] = group['act']-group['che']-group['lct']+group['dlc']\n",
    "     group['NCO']= group['at']-group['act']-group['lt']+group['lct']+group['dltt']\n",
    "     group['FIN']= group['ivst']-group['dltt']-group['dlc']-group['pstk']\n",
    "     group['TACC_t'] = (group['WC']+group['NCO']+group['FIN'])/group['csho']\n",
    "\n",
    "    # Create dummy variables for dividend and retained earnings\n",
    "     group['dummy_Neg_E_t'] = group['E_t'].apply(lambda x: 1 if x < 0 else 0)\n",
    "     group['dummy_Div'] = group['dvc'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "     group['Neg_E_interaction_term'] = group['dummy_Neg_E_t']*group['EPS']\n",
    "     return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d106afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the data by gvkey code\n",
    "# This is to make sure that the data we use is for one company only and that it doesnot take values from a row above that belongs to some other company\n",
    "df = df.groupby('gvkey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4f08cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill all remaining None Type values with zero\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a44d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the calc_deltas function to each group\n",
    "delta_df = df.apply(calc_deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f097f8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>tic</th>\n",
       "      <th>conm</th>\n",
       "      <th>invch</th>\n",
       "      <th>sic</th>\n",
       "      <th>prcc_f</th>\n",
       "      <th>fyear</th>\n",
       "      <th>cusip</th>\n",
       "      <th>industry</th>\n",
       "      <th>ib</th>\n",
       "      <th>...</th>\n",
       "      <th>E_t2_EP_RI</th>\n",
       "      <th>E_t3_EP_RI</th>\n",
       "      <th>B_t</th>\n",
       "      <th>WC</th>\n",
       "      <th>NCO</th>\n",
       "      <th>FIN</th>\n",
       "      <th>TACC_t</th>\n",
       "      <th>dummy_Neg_E_t</th>\n",
       "      <th>dummy_Div</th>\n",
       "      <th>Neg_E_interaction_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001004</td>\n",
       "      <td>AIR</td>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>-34.615</td>\n",
       "      <td>5080</td>\n",
       "      <td>26.3900</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>000361105</td>\n",
       "      <td>50</td>\n",
       "      <td>73.139</td>\n",
       "      <td>...</td>\n",
       "      <td>1.912973</td>\n",
       "      <td>1.832533</td>\n",
       "      <td>21.011161</td>\n",
       "      <td>554.617</td>\n",
       "      <td>667.116</td>\n",
       "      <td>-443.877</td>\n",
       "      <td>19.553455</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001004</td>\n",
       "      <td>AIR</td>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>-42.057</td>\n",
       "      <td>5080</td>\n",
       "      <td>12.0500</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>000361105</td>\n",
       "      <td>50</td>\n",
       "      <td>67.723</td>\n",
       "      <td>...</td>\n",
       "      <td>1.810146</td>\n",
       "      <td>-0.151466</td>\n",
       "      <td>21.469694</td>\n",
       "      <td>645.191</td>\n",
       "      <td>945.465</td>\n",
       "      <td>-792.354</td>\n",
       "      <td>19.822263</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001004</td>\n",
       "      <td>AIR</td>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>26.500</td>\n",
       "      <td>5080</td>\n",
       "      <td>20.0600</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>000361105</td>\n",
       "      <td>50</td>\n",
       "      <td>55.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154893</td>\n",
       "      <td>1.038546</td>\n",
       "      <td>23.325377</td>\n",
       "      <td>655.800</td>\n",
       "      <td>897.000</td>\n",
       "      <td>-708.600</td>\n",
       "      <td>21.436189</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001004</td>\n",
       "      <td>AIR</td>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>-36.600</td>\n",
       "      <td>5080</td>\n",
       "      <td>24.3000</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>000361105</td>\n",
       "      <td>50</td>\n",
       "      <td>72.900</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033873</td>\n",
       "      <td>1.203236</td>\n",
       "      <td>25.265420</td>\n",
       "      <td>695.300</td>\n",
       "      <td>850.200</td>\n",
       "      <td>-634.000</td>\n",
       "      <td>23.040950</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>001004</td>\n",
       "      <td>AIR</td>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>-36.600</td>\n",
       "      <td>5080</td>\n",
       "      <td>29.5400</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>000361105</td>\n",
       "      <td>50</td>\n",
       "      <td>-54.500</td>\n",
       "      <td>...</td>\n",
       "      <td>1.343760</td>\n",
       "      <td>2.080569</td>\n",
       "      <td>23.857381</td>\n",
       "      <td>556.400</td>\n",
       "      <td>388.000</td>\n",
       "      <td>-154.000</td>\n",
       "      <td>22.313186</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.172204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160393</th>\n",
       "      <td>351038</td>\n",
       "      <td>QNRX</td>\n",
       "      <td>CELLECT BIOTECHNOLOGY LTD</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2834</td>\n",
       "      <td>1.4200</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>74907L201</td>\n",
       "      <td>28</td>\n",
       "      <td>-9.381</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.528162</td>\n",
       "      <td>-3.012</td>\n",
       "      <td>-2.435</td>\n",
       "      <td>9.993</td>\n",
       "      <td>0.937900</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.021250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160397</th>\n",
       "      <td>351491</td>\n",
       "      <td>IVCGF</td>\n",
       "      <td>IVECO GROUP N V</td>\n",
       "      <td>-234.055</td>\n",
       "      <td>3711</td>\n",
       "      <td>5.8800</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>N47017103</td>\n",
       "      <td>37</td>\n",
       "      <td>157.105</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.272164</td>\n",
       "      <td>12454.053</td>\n",
       "      <td>-7606.238</td>\n",
       "      <td>-4738.803</td>\n",
       "      <td>0.401939</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160400</th>\n",
       "      <td>351590</td>\n",
       "      <td>DTRUY</td>\n",
       "      <td>DAIMLER TRUCK HOLDING AG</td>\n",
       "      <td>-1486.484</td>\n",
       "      <td>3713</td>\n",
       "      <td>18.4389</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>23384L101</td>\n",
       "      <td>37</td>\n",
       "      <td>2669.303</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.000778</td>\n",
       "      <td>9934.541</td>\n",
       "      <td>19264.022</td>\n",
       "      <td>-18759.051</td>\n",
       "      <td>6.342722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160401</th>\n",
       "      <td>351590</td>\n",
       "      <td>DTRUY</td>\n",
       "      <td>DAIMLER TRUCK HOLDING AG</td>\n",
       "      <td>-1221.573</td>\n",
       "      <td>3713</td>\n",
       "      <td>15.4460</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>23384L101</td>\n",
       "      <td>37</td>\n",
       "      <td>2848.198</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.020455</td>\n",
       "      <td>12650.702</td>\n",
       "      <td>24089.451</td>\n",
       "      <td>-21070.255</td>\n",
       "      <td>9.520542</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160403</th>\n",
       "      <td>353444</td>\n",
       "      <td>HLN</td>\n",
       "      <td>HALEON PLC</td>\n",
       "      <td>-351.831</td>\n",
       "      <td>2834</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>405552100</td>\n",
       "      <td>28</td>\n",
       "      <td>1277.194</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.261642</td>\n",
       "      <td>-672.334</td>\n",
       "      <td>32256.378</td>\n",
       "      <td>-12579.157</td>\n",
       "      <td>4.116029</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73164 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         gvkey    tic                       conm     invch   sic   prcc_f  \\\n",
       "2       001004    AIR                   AAR CORP   -34.615  5080  26.3900   \n",
       "3       001004    AIR                   AAR CORP   -42.057  5080  12.0500   \n",
       "4       001004    AIR                   AAR CORP    26.500  5080  20.0600   \n",
       "5       001004    AIR                   AAR CORP   -36.600  5080  24.3000   \n",
       "6       001004    AIR                   AAR CORP   -36.600  5080  29.5400   \n",
       "...        ...    ...                        ...       ...   ...      ...   \n",
       "160393  351038   QNRX  CELLECT BIOTECHNOLOGY LTD     0.000  2834   1.4200   \n",
       "160397  351491  IVCGF            IVECO GROUP N V  -234.055  3711   5.8800   \n",
       "160400  351590  DTRUY   DAIMLER TRUCK HOLDING AG -1486.484  3713  18.4389   \n",
       "160401  351590  DTRUY   DAIMLER TRUCK HOLDING AG -1221.573  3713  15.4460   \n",
       "160403  353444    HLN                 HALEON PLC  -351.831  2834   8.0000   \n",
       "\n",
       "         fyear      cusip  industry        ib  ...  E_t2_EP_RI  E_t3_EP_RI  \\\n",
       "2       2010.0  000361105        50    73.139  ...    1.912973    1.832533   \n",
       "3       2011.0  000361105        50    67.723  ...    1.810146   -0.151466   \n",
       "4       2012.0  000361105        50    55.000  ...   -0.154893    1.038546   \n",
       "5       2013.0  000361105        50    72.900  ...    1.033873    1.203236   \n",
       "6       2014.0  000361105        50   -54.500  ...    1.343760    2.080569   \n",
       "...        ...        ...       ...       ...  ...         ...         ...   \n",
       "160393  2022.0  74907L201        28    -9.381  ...         NaN         NaN   \n",
       "160397  2022.0  N47017103        37   157.105  ...         NaN         NaN   \n",
       "160400  2021.0  23384L101        37  2669.303  ...         NaN         NaN   \n",
       "160401  2022.0  23384L101        37  2848.198  ...         NaN         NaN   \n",
       "160403  2022.0  405552100        28  1277.194  ...         NaN         NaN   \n",
       "\n",
       "              B_t         WC        NCO        FIN     TACC_t  dummy_Neg_E_t  \\\n",
       "2       21.011161    554.617    667.116   -443.877  19.553455              0   \n",
       "3       21.469694    645.191    945.465   -792.354  19.822263              0   \n",
       "4       23.325377    655.800    897.000   -708.600  21.436189              0   \n",
       "5       25.265420    695.300    850.200   -634.000  23.040950              0   \n",
       "6       23.857381    556.400    388.000   -154.000  22.313186              1   \n",
       "...           ...        ...        ...        ...        ...            ...   \n",
       "160393   1.528162     -3.012     -2.435      9.993   0.937900              1   \n",
       "160397   9.272164  12454.053  -7606.238  -4738.803   0.401939              0   \n",
       "160400  11.000778   9934.541  19264.022 -18759.051   6.342722              0   \n",
       "160401  13.020455  12650.702  24089.451 -21070.255   9.520542              0   \n",
       "160403   4.261642   -672.334  32256.378 -12579.157   4.116029              0   \n",
       "\n",
       "        dummy_Div  Neg_E_interaction_term  \n",
       "2               1                0.000000  \n",
       "3               1                0.000000  \n",
       "4               1                0.000000  \n",
       "5               1                0.000000  \n",
       "6               1               -0.172204  \n",
       "...           ...                     ...  \n",
       "160393          1               -2.021250  \n",
       "160397          1                0.000000  \n",
       "160400          1                0.000000  \n",
       "160401          1                0.000000  \n",
       "160403          1                0.000000  \n",
       "\n",
       "[73164 rows x 48 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcf63ee",
   "metadata": {},
   "source": [
    "#### winsorize columns at yearly level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edd892d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\1103843939.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = winsorize(df_year[col], limits=(0.01, 0.01))\n",
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\1103843939.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = winsorize(df_year[col], limits=(0.01, 0.01))\n",
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\1103843939.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = winsorize(df_year[col], limits=(0.01, 0.01))\n",
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\1103843939.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = winsorize(df_year[col], limits=(0.01, 0.01))\n",
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\1103843939.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = winsorize(df_year[col], limits=(0.01, 0.01))\n",
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\1103843939.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = winsorize(df_year[col], limits=(0.01, 0.01))\n",
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\1103843939.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = winsorize(df_year[col], limits=(0.01, 0.01))\n",
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\1103843939.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = winsorize(df_year[col], limits=(0.01, 0.01))\n",
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\1103843939.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = winsorize(df_year[col], limits=(0.01, 0.01))\n",
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\1103843939.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = winsorize(df_year[col], limits=(0.01, 0.01))\n",
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\1103843939.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = winsorize(df_year[col], limits=(0.01, 0.01))\n",
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\1103843939.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = winsorize(df_year[col], limits=(0.01, 0.01))\n",
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\1103843939.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = winsorize(df_year[col], limits=(0.01, 0.01))\n"
     ]
    }
   ],
   "source": [
    "# Create an empty data frame to hold the winsorized data\n",
    "df_win = pd.DataFrame()\n",
    "\n",
    "# List of columns to winsorize\n",
    "cols_to_winsorize = ['at','dvc','E_t','dummy_Neg_E_t','ACT','Neg_E_interaction_term','B_t','TACC_t',\n",
    "                     'E_t1_HVZ','E_t2_HVZ','E_t3_HVZ','E_t1_EP_RI','E_t2_EP_RI','E_t3_EP_RI']\n",
    "\n",
    "# Winsorize by year\n",
    "for year in delta_df['fyear'].unique():\n",
    "    # Subset the data for the current year\n",
    "    df_year = delta_df[delta_df['fyear'] == year]\n",
    "    \n",
    "    # Winsorize the columns for the current year's data\n",
    "    for col in cols_to_winsorize:\n",
    "        df_year[col] = winsorize(df_year[col], limits=(0.01, 0.01))\n",
    "    \n",
    "    # Append the winsorized data for the current year to df_winsorized\n",
    "    df_win = pd.concat([df_win, df_year])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701f5522",
   "metadata": {},
   "source": [
    "#### Additional Cleaning Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "202d776b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows containing at least one NaN value: 36679\n"
     ]
    }
   ],
   "source": [
    "# count the number of rows that contain at least one NaN value\n",
    "nan_count = df_win[cols_to_winsorize].isna().sum(axis=1).astype(bool).sum()\n",
    "\n",
    "# print the count of rows containing at least one NaN value\n",
    "print(\"Number of rows containing at least one NaN value:\", nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "541fe479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11046 11046\n"
     ]
    }
   ],
   "source": [
    "print(df_win['E_t1_HVZ'].isna().sum(), df_win['E_t1_EP_RI'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845402e6",
   "metadata": {},
   "source": [
    "We will drop these NAN values during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67b73347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# check for inf values and replace them with NAN for now \n",
    "cols_inf = ['EPS', 'E_t1_EP_RI','E_t2_EP_RI','E_t3_EP_RI']\n",
    "df_win[cols_inf] = df_win[cols_inf].replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d89bc5",
   "metadata": {},
   "source": [
    "#### Split in training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4c65cec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset = 2010-2019 Test dataset = 2020, 2021, and 2022\n",
    "# split data into training and test datasets based on date\n",
    "train_data = df_win[(df_win['fyear'] >= 2010) & (df_win['fyear'] <= 2018)]\n",
    "test_data_2019 = df_win[df_win['fyear'] == 2019]\n",
    "test_data_2020 = df_win[df_win['fyear'] == 2020]\n",
    "test_data_2021 = df_win[df_win['fyear'] == 2021]\n",
    "test_data_2022 = df_win[df_win['fyear'] == 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4946b6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52528\n",
      "5286\n",
      "5635\n",
      "4404\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape[0])\n",
    "print(test_data_2020.shape[0])\n",
    "print(test_data_2021.shape[0])\n",
    "print(test_data_2022.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55adcd0d",
   "metadata": {},
   "source": [
    "#### Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "533676ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "# Define Regression Function\n",
    "def ols(input_data, input_y, input_X):\n",
    "    Y = input_data[input_y]\n",
    "    X = input_data[input_X]\n",
    "    X['intercept'] = 1.0\n",
    "    model = sm.OLS(Y, X).fit()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3ec127",
   "metadata": {},
   "source": [
    "### HVZ model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b2aa64",
   "metadata": {},
   "source": [
    "#### HVZ model for earnings in year E_t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7ea1feca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\2881450415.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['intercept'] = 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>E_t1_HVZ</td>     <th>  R-squared:         </th>  <td>   0.603</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.603</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>1.201e+04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 May 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:35:28</td>     <th>  Log-Likelihood:    </th> <td>-3.2762e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 39470</td>      <th>  AIC:               </th>  <td>6.553e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 39464</td>      <th>  BIC:               </th>  <td>6.553e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>at</th>            <td>    0.0098</td> <td>    0.001</td> <td>   10.860</td> <td> 0.000</td> <td>    0.008</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dvc</th>           <td>    0.4608</td> <td>    0.030</td> <td>   15.554</td> <td> 0.000</td> <td>    0.403</td> <td>    0.519</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>E_t</th>           <td>    1.1351</td> <td>    0.014</td> <td>   81.473</td> <td> 0.000</td> <td>    1.108</td> <td>    1.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dummy_Neg_E_t</th> <td>  128.5473</td> <td>   10.299</td> <td>   12.482</td> <td> 0.000</td> <td>  108.362</td> <td>  148.733</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACT</th>           <td>   -0.1564</td> <td>    0.014</td> <td>  -11.536</td> <td> 0.000</td> <td>   -0.183</td> <td>   -0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>     <td> -126.0783</td> <td>    7.385</td> <td>  -17.073</td> <td> 0.000</td> <td> -140.552</td> <td> -111.604</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>87983.314</td> <th>  Durbin-Watson:     </th>   <td>   1.982</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>982131707.831</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>20.638</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>774.679</td>  <th>  Cond. No.          </th>   <td>3.47e+04</td>   \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.47e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               E_t1_HVZ   R-squared:                       0.603\n",
       "Model:                            OLS   Adj. R-squared:                  0.603\n",
       "Method:                 Least Squares   F-statistic:                 1.201e+04\n",
       "Date:                Sat, 06 May 2023   Prob (F-statistic):               0.00\n",
       "Time:                        18:35:28   Log-Likelihood:            -3.2762e+05\n",
       "No. Observations:               39470   AIC:                         6.553e+05\n",
       "Df Residuals:                   39464   BIC:                         6.553e+05\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "at                0.0098      0.001     10.860      0.000       0.008       0.012\n",
       "dvc               0.4608      0.030     15.554      0.000       0.403       0.519\n",
       "E_t               1.1351      0.014     81.473      0.000       1.108       1.162\n",
       "dummy_Neg_E_t   128.5473     10.299     12.482      0.000     108.362     148.733\n",
       "ACT              -0.1564      0.014    -11.536      0.000      -0.183      -0.130\n",
       "intercept      -126.0783      7.385    -17.073      0.000    -140.552    -111.604\n",
       "==============================================================================\n",
       "Omnibus:                    87983.314   Durbin-Watson:                   1.982\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        982131707.831\n",
       "Skew:                          20.638   Prob(JB):                         0.00\n",
       "Kurtosis:                     774.679   Cond. No.                     3.47e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.47e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvz_train_t1 = train_data.dropna(subset=['at','dvc','E_t','dummy_Neg_E_t','ACT','E_t1_HVZ'])\n",
    "\n",
    "# Estimate coefficients for HVZ Model at industry and fyear level\n",
    "hvz_model_t1 = ols(hvz_train_t1,'E_t1_HVZ',['at','dvc','E_t','dummy_Neg_E_t','ACT'])\n",
    "params_hvz_model_t1 = hvz_model_t1.params\n",
    "hvz_model_t1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f8f49d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for 2020: 288.4273379069446\n",
      "MSE for 2020: 1000252.2045708699\n",
      "RMSE for 2020: 1000.1260943355443\n",
      "Mean bias: 180.26547279428527\n",
      "Median bias: 1.173710421585402\n",
      "p-value for mean bias: 1.057375202057314e-34\n",
      "p-value for median bias: 2.7903872681919336e-34\n",
      "Mean accuracy: 0.6492380679881898\n",
      "Median accuracy: 1.124919264206976\n",
      "p-value for mean accuracy: 0.9624994442575054\n",
      "p-value for median accuracy: 0.9491598315821204\n",
      "t-statistic: 12.390322200184038\n",
      "p-value for t-statistic: 1.057375202057314e-34\n"
     ]
    }
   ],
   "source": [
    "# Testing Accuracy on out of sample data\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import ttest_1samp\n",
    "# Select the same columns as used in training the model\n",
    "hvz_test_t1 = test_data_2019[['gvkey','at','dvc','E_t','dummy_Neg_E_t','ACT']].dropna()\n",
    "hvz_test_t1 = hvz_test_t1.set_index('gvkey')\n",
    "# Make predictions using the model for 2020 test data\n",
    "y_pred_2020 = hvz_test_t1.apply(lambda row: params_hvz_model_t1['intercept'] + \\\n",
    "    params_hvz_model_t1['at']*row['at'] + params_hvz_model_t1['dvc']*row['dvc'] + \\\n",
    "    params_hvz_model_t1['E_t']*row['E_t'] + params_hvz_model_t1['dummy_Neg_E_t']*row['dummy_Neg_E_t'] + \\\n",
    "    params_hvz_model_t1['ACT']*row['ACT'], axis=1)\n",
    "\n",
    "# Reset the index of the y_pred_2020 DataFrame\n",
    "y_pred_2020 = y_pred_2020.reset_index()\n",
    "y_pred_2020\n",
    "y_true_2020 = test_data_2020[['gvkey', 'E_t']]\n",
    "merged_df = y_true_2020.merge(y_pred_2020, on='gvkey')\n",
    "# Rename the predicted column\n",
    "merged_df = merged_df.rename(columns={0: 'predicted'})\n",
    "\n",
    "# Calculate accuracy for 2020\n",
    "mae_2020 = mean_absolute_error(merged_df['E_t'], merged_df['predicted'])\n",
    "mse_2020 = mean_squared_error(merged_df['E_t'], merged_df['predicted'])\n",
    "rmse_2020 = mean_squared_error(merged_df['E_t'], merged_df['predicted'], squared=False)\n",
    "\n",
    "print(\"MAE for 2020:\", mae_2020)\n",
    "print(\"MSE for 2020:\", mse_2020)\n",
    "print(\"RMSE for 2020:\", rmse_2020)\n",
    "\n",
    "# Calculate bias and accuracy\n",
    "y_true = merged_df['E_t']\n",
    "y_pred = merged_df['predicted']\n",
    "bias = y_pred - y_true\n",
    "accuracy = 1 - abs(bias) / (y_true + 1e-9)\n",
    "\n",
    "# Compute mean and median of bias and accuracy\n",
    "bias_mean = bias.mean()\n",
    "bias_median = bias.median()\n",
    "accuracy_mean = accuracy.mean()\n",
    "accuracy_median = accuracy.median()\n",
    "from scipy.stats import ttest_rel\n",
    "# Compute p-values for mean and median bias and accuracy\n",
    "_, pval_bias_mean = ttest_1samp(bias, 0)\n",
    "_, pval_bias_median = ttest_1samp(bias, bias_median)\n",
    "_, pval_accuracy_mean = ttest_1samp(accuracy, 1)\n",
    "_, pval_accuracy_median = ttest_1samp(accuracy, accuracy_median)\n",
    "\n",
    "# Compute t-statistic\n",
    "t_statistic, p_value = ttest_rel(y_pred, y_true)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean bias: {bias_mean}\")\n",
    "print(f\"Median bias: {bias_median}\")\n",
    "print(f\"p-value for mean bias: {pval_bias_mean}\")\n",
    "print(f\"p-value for median bias: {pval_bias_median}\")\n",
    "print(f\"Mean accuracy: {accuracy_mean}\")\n",
    "print(f\"Median accuracy: {accuracy_median}\")\n",
    "print(f\"p-value for mean accuracy: {pval_accuracy_mean}\")\n",
    "print(f\"p-value for median accuracy: {pval_accuracy_median}\")\n",
    "print(f\"t-statistic: {t_statistic}\")\n",
    "print(f\"p-value for t-statistic: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f580cdbd",
   "metadata": {},
   "source": [
    "#### HVZ model for earnings in year E_t+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6cb02de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\2881450415.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['intercept'] = 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>E_t2_HVZ</td>     <th>  R-squared:         </th>  <td>   0.550</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.550</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   8858.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 May 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:36:25</td>     <th>  Log-Likelihood:    </th> <td>-3.0456e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 36221</td>      <th>  AIC:               </th>  <td>6.091e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 36215</td>      <th>  BIC:               </th>  <td>6.092e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>at</th>            <td>    0.0153</td> <td>    0.001</td> <td>   15.034</td> <td> 0.000</td> <td>    0.013</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dvc</th>           <td>    0.5520</td> <td>    0.034</td> <td>   16.403</td> <td> 0.000</td> <td>    0.486</td> <td>    0.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>E_t</th>           <td>    0.9537</td> <td>    0.016</td> <td>   60.436</td> <td> 0.000</td> <td>    0.923</td> <td>    0.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dummy_Neg_E_t</th> <td>  112.4974</td> <td>   11.998</td> <td>    9.376</td> <td> 0.000</td> <td>   88.981</td> <td>  136.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACT</th>           <td>   -0.1564</td> <td>    0.015</td> <td>  -10.200</td> <td> 0.000</td> <td>   -0.186</td> <td>   -0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>     <td> -110.8751</td> <td>    8.503</td> <td>  -13.040</td> <td> 0.000</td> <td> -127.541</td> <td>  -94.209</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>75758.410</td> <th>  Durbin-Watson:     </th>   <td>   1.976</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>639596394.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>17.737</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>653.029</td>  <th>  Cond. No.          </th>   <td>3.57e+04</td>   \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.57e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               E_t2_HVZ   R-squared:                       0.550\n",
       "Model:                            OLS   Adj. R-squared:                  0.550\n",
       "Method:                 Least Squares   F-statistic:                     8858.\n",
       "Date:                Sat, 06 May 2023   Prob (F-statistic):               0.00\n",
       "Time:                        18:36:25   Log-Likelihood:            -3.0456e+05\n",
       "No. Observations:               36221   AIC:                         6.091e+05\n",
       "Df Residuals:                   36215   BIC:                         6.092e+05\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "at                0.0153      0.001     15.034      0.000       0.013       0.017\n",
       "dvc               0.5520      0.034     16.403      0.000       0.486       0.618\n",
       "E_t               0.9537      0.016     60.436      0.000       0.923       0.985\n",
       "dummy_Neg_E_t   112.4974     11.998      9.376      0.000      88.981     136.014\n",
       "ACT              -0.1564      0.015    -10.200      0.000      -0.186      -0.126\n",
       "intercept      -110.8751      8.503    -13.040      0.000    -127.541     -94.209\n",
       "==============================================================================\n",
       "Omnibus:                    75758.410   Durbin-Watson:                   1.976\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        639596394.188\n",
       "Skew:                          17.737   Prob(JB):                         0.00\n",
       "Kurtosis:                     653.029   Cond. No.                     3.57e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.57e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvz_train_t2 = train_data.dropna(subset=['at','dvc','E_t','dummy_Neg_E_t','ACT','E_t2_HVZ'])\n",
    "\n",
    "# Estimate coefficients for HVZ Model at industry and fyear level\n",
    "hvz_model_t2 = ols(hvz_train_t2,'E_t2_HVZ',['at','dvc','E_t','dummy_Neg_E_t','ACT'])\n",
    "params_hvz_model_t2 = hvz_model_t2.params\n",
    "hvz_model_t2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "815accaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for 2021: 232.6919477161709\n",
      "MSE for 2021: 449754.1448010612\n",
      "RMSE for 2021: 670.6371185679042\n",
      "Mean bias: 32.59971329773349\n",
      "Median bias: -0.37595881755670035\n",
      "p-value for mean bias: 0.0014521566592394718\n",
      "p-value for median bias: 0.0012785343618017865\n",
      "Mean accuracy: 0.6053714349167623\n",
      "Median accuracy: 0.9299385196859302\n",
      "p-value for mean accuracy: 0.963450318041863\n",
      "p-value for median accuracy: 0.9699358629460615\n",
      "t-statistic: 3.18614832376883\n",
      "p-value for t-statistic: 0.0014521566592394718\n"
     ]
    }
   ],
   "source": [
    "# Testing Accuracy on out of sample data\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import ttest_1samp\n",
    "# Select the same columns as used in training the model\n",
    "hvz_test_t2 = test_data_2019[['gvkey','at','dvc','E_t','dummy_Neg_E_t','ACT']].dropna()\n",
    "hvz_test_t2 = hvz_test_t2.set_index('gvkey')\n",
    "# Make predictions using the model for 2020 test data\n",
    "y_pred_2021 = hvz_test_t2.apply(lambda row: params_hvz_model_t2['intercept'] + \\\n",
    "    params_hvz_model_t2['at']*row['at'] + params_hvz_model_t2['dvc']*row['dvc'] + \\\n",
    "    params_hvz_model_t2['E_t']*row['E_t'] + params_hvz_model_t2['dummy_Neg_E_t']*row['dummy_Neg_E_t'] + \\\n",
    "    params_hvz_model_t2['ACT']*row['ACT'], axis=1)\n",
    "\n",
    "# Reset the index of the y_pred_2021 DataFrame\n",
    "y_pred_2021 = y_pred_2021.reset_index()\n",
    "y_pred_2021\n",
    "y_true_2021 = test_data_2021[['gvkey', 'E_t']]\n",
    "merged_df = y_true_2021.merge(y_pred_2021, on='gvkey')\n",
    "# Rename the predicted column\n",
    "merged_df = merged_df.rename(columns={0: 'predicted'})\n",
    "\n",
    "# Calculate accuracy for 2021\n",
    "mae_2021 = mean_absolute_error(merged_df['E_t'], merged_df['predicted'])\n",
    "mse_2021 = mean_squared_error(merged_df['E_t'], merged_df['predicted'])\n",
    "rmse_2021 = mean_squared_error(merged_df['E_t'], merged_df['predicted'], squared=False)\n",
    "\n",
    "print(\"MAE for 2021:\", mae_2021)\n",
    "print(\"MSE for 2021:\", mse_2021)\n",
    "print(\"RMSE for 2021:\", rmse_2021)\n",
    "\n",
    "# Calculate bias and accuracy\n",
    "y_true = merged_df['E_t']\n",
    "y_pred = merged_df['predicted']\n",
    "bias = y_pred - y_true\n",
    "accuracy = 1 - abs(bias) / (y_true + 1e-9)\n",
    "\n",
    "# Compute mean and median of bias and accuracy\n",
    "bias_mean = bias.mean()\n",
    "bias_median = bias.median()\n",
    "accuracy_mean = accuracy.mean()\n",
    "accuracy_median = accuracy.median()\n",
    "from scipy.stats import ttest_rel\n",
    "# Compute p-values for mean and median bias and accuracy\n",
    "_, pval_bias_mean = ttest_1samp(bias, 0)\n",
    "_, pval_bias_median = ttest_1samp(bias, bias_median)\n",
    "_, pval_accuracy_mean = ttest_1samp(accuracy, 1)\n",
    "_, pval_accuracy_median = ttest_1samp(accuracy, accuracy_median)\n",
    "\n",
    "# Compute t-statistic\n",
    "t_statistic, p_value = ttest_rel(y_pred, y_true)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean bias: {bias_mean}\")\n",
    "print(f\"Median bias: {bias_median}\")\n",
    "print(f\"p-value for mean bias: {pval_bias_mean}\")\n",
    "print(f\"p-value for median bias: {pval_bias_median}\")\n",
    "print(f\"Mean accuracy: {accuracy_mean}\")\n",
    "print(f\"Median accuracy: {accuracy_median}\")\n",
    "print(f\"p-value for mean accuracy: {pval_accuracy_mean}\")\n",
    "print(f\"p-value for median accuracy: {pval_accuracy_median}\")\n",
    "print(f\"t-statistic: {t_statistic}\")\n",
    "print(f\"p-value for t-statistic: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f2fb52",
   "metadata": {},
   "source": [
    "#### HVZ model for earnings in year E_t+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "39111274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\2881450415.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['intercept'] = 1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>E_t3_HVZ</td>     <th>  R-squared:         </th>  <td>   0.521</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.521</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   7256.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 May 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:43:43</td>     <th>  Log-Likelihood:    </th> <td>-2.8549e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 33314</td>      <th>  AIC:               </th>  <td>5.710e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 33308</td>      <th>  BIC:               </th>  <td>5.710e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>at</th>            <td>    0.0197</td> <td>    0.001</td> <td>   16.184</td> <td> 0.000</td> <td>    0.017</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dvc</th>           <td>    0.4749</td> <td>    0.040</td> <td>   11.770</td> <td> 0.000</td> <td>    0.396</td> <td>    0.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>E_t</th>           <td>    1.0428</td> <td>    0.019</td> <td>   55.285</td> <td> 0.000</td> <td>    1.006</td> <td>    1.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dummy_Neg_E_t</th> <td>  135.1292</td> <td>   14.734</td> <td>    9.171</td> <td> 0.000</td> <td>  106.249</td> <td>  164.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACT</th>           <td>   -0.1365</td> <td>    0.018</td> <td>   -7.505</td> <td> 0.000</td> <td>   -0.172</td> <td>   -0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>     <td> -125.9376</td> <td>   10.335</td> <td>  -12.186</td> <td> 0.000</td> <td> -146.194</td> <td> -105.681</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>76061.763</td> <th>  Durbin-Watson:     </th>    <td>   1.978</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>1335437784.363</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>21.669</td>   <th>  Prob(JB):          </th>    <td>    0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>982.895</td>  <th>  Cond. No.          </th>    <td>3.68e+04</td>   \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.68e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               E_t3_HVZ   R-squared:                       0.521\n",
       "Model:                            OLS   Adj. R-squared:                  0.521\n",
       "Method:                 Least Squares   F-statistic:                     7256.\n",
       "Date:                Sat, 06 May 2023   Prob (F-statistic):               0.00\n",
       "Time:                        18:43:43   Log-Likelihood:            -2.8549e+05\n",
       "No. Observations:               33314   AIC:                         5.710e+05\n",
       "Df Residuals:                   33308   BIC:                         5.710e+05\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "at                0.0197      0.001     16.184      0.000       0.017       0.022\n",
       "dvc               0.4749      0.040     11.770      0.000       0.396       0.554\n",
       "E_t               1.0428      0.019     55.285      0.000       1.006       1.080\n",
       "dummy_Neg_E_t   135.1292     14.734      9.171      0.000     106.249     164.009\n",
       "ACT              -0.1365      0.018     -7.505      0.000      -0.172      -0.101\n",
       "intercept      -125.9376     10.335    -12.186      0.000    -146.194    -105.681\n",
       "==============================================================================\n",
       "Omnibus:                    76061.763   Durbin-Watson:                   1.978\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):       1335437784.363\n",
       "Skew:                          21.669   Prob(JB):                         0.00\n",
       "Kurtosis:                     982.895   Cond. No.                     3.68e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.68e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvz_train_t3 = train_data.dropna(subset=['at','dvc','E_t','dummy_Neg_E_t','ACT','E_t3_HVZ'])\n",
    "\n",
    "# Estimate coefficients for HVZ Model at industry and fyear level\n",
    "hvz_model_t3 = ols(hvz_train_t3,'E_t3_HVZ',['at','dvc','E_t','dummy_Neg_E_t','ACT'])\n",
    "params_hvz_model_t3 = hvz_model_t3.params\n",
    "hvz_model_t3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b4ba6132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for 2022: 299.7624810666547\n",
      "MSE for 2022: 697544.0074306902\n",
      "RMSE for 2022: 835.1910005685468\n",
      "Mean bias: 22.82701373605013\n",
      "Median bias: 2.1742342969800994\n",
      "p-value for mean bias: 0.12256550289222676\n",
      "p-value for median bias: 0.16239275333401818\n",
      "Mean accuracy: -46.45491153325111\n",
      "Median accuracy: 0.8293347336836914\n",
      "p-value for mean accuracy: 0.2574412766845269\n",
      "p-value for median accuracy: 0.25915624768066126\n",
      "t-statistic: 1.5445037534573776\n",
      "p-value for t-statistic: 0.12256550289222676\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "# Select the same columns as used in training the model\n",
    "hvz_test_t3 = test_data_2019[['gvkey','at','dvc','E_t','dummy_Neg_E_t','ACT']].dropna()\n",
    "hvz_test_t3 = hvz_test_t3.set_index('gvkey')\n",
    "\n",
    "# Make predictions using the model for 2022 test data\n",
    "y_pred_2022 = hvz_test_t3.apply(lambda row: params_hvz_model_t3['intercept'] + \\\n",
    "    params_hvz_model_t3['at']*row['at'] + params_hvz_model_t3['dvc']*row['dvc'] + \\\n",
    "    params_hvz_model_t3['E_t']*row['E_t'] + params_hvz_model_t3['dummy_Neg_E_t']*row['dummy_Neg_E_t'] + \\\n",
    "    params_hvz_model_t3['ACT']*row['ACT'], axis=1)\n",
    "\n",
    "# Reset the index of the y_pred_2022 DataFrame\n",
    "y_pred_2022 = y_pred_2022.reset_index()\n",
    "\n",
    "y_true_2022 = test_data_2022[['gvkey', 'E_t']]\n",
    "merged_df = y_true_2022.merge(y_pred_2022, on='gvkey')\n",
    "\n",
    "# Rename the predicted column\n",
    "merged_df = merged_df.rename(columns={0: 'predicted'})\n",
    "\n",
    "# Calculate accuracy for 2022\n",
    "mae_2022 = mean_absolute_error(merged_df['E_t'], merged_df['predicted'])\n",
    "mse_2022 = mean_squared_error(merged_df['E_t'], merged_df['predicted'])\n",
    "rmse_2022 = mean_squared_error(merged_df['E_t'], merged_df['predicted'], squared=False)\n",
    "\n",
    "print(\"MAE for 2022:\", mae_2022)\n",
    "print(\"MSE for 2022:\", mse_2022)\n",
    "print(\"RMSE for 2022:\", rmse_2022)\n",
    "\n",
    "# Calculate bias and accuracy\n",
    "y_true = merged_df['E_t']\n",
    "y_pred = merged_df['predicted']\n",
    "bias = y_pred - y_true\n",
    "accuracy = 1 - abs(bias) / (y_true + 1e-9)\n",
    "\n",
    "# Compute mean and median of bias and accuracy\n",
    "bias_mean = bias.mean()\n",
    "bias_median = bias.median()\n",
    "accuracy_mean = accuracy.mean()\n",
    "accuracy_median = accuracy.median()\n",
    "\n",
    "# Compute p-values for mean and median bias and accuracy\n",
    "_, pval_bias_mean = ttest_1samp(bias, 0)\n",
    "_, pval_bias_median = ttest_1samp(bias, bias_median)\n",
    "_, pval_accuracy_mean = ttest_1samp(accuracy, 1)\n",
    "_, pval_accuracy_median = ttest_1samp(accuracy, accuracy_median)\n",
    "\n",
    "# Compute t-statistic\n",
    "t_statistic, p_value = ttest_rel(y_pred, y_true)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean bias: {bias_mean}\")\n",
    "print(f\"Median bias: {bias_median}\")\n",
    "print(f\"p-value for mean bias: {pval_bias_mean}\")\n",
    "print(f\"p-value for median bias: {pval_bias_median}\")\n",
    "print(f\"Mean accuracy: {accuracy_mean}\")\n",
    "print(f\"Median accuracy: {accuracy_median}\")\n",
    "print(f\"p-value for mean accuracy: {pval_accuracy_mean}\")\n",
    "print(f\"p-value for median accuracy: {pval_accuracy_median}\")\n",
    "print(f\"t-statistic: {t_statistic}\")\n",
    "print(f\"p-value for t-statistic: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e6930b",
   "metadata": {},
   "source": [
    "## Earnings Persistence Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db68f8e",
   "metadata": {},
   "source": [
    "#### EP model for earnings in year E_t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "33b81e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>E_t1_EP_RI</td>    <th>  R-squared:         </th>  <td>   0.051</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.051</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   870.1</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 May 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:49:41</td>     <th>  Log-Likelihood:    </th> <td>-3.3664e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 48142</td>      <th>  AIC:               </th>  <td>6.733e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 48138</td>      <th>  BIC:               </th>  <td>6.733e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dummy_Neg_E_t</th>          <td>   -5.4602</td> <td>    2.587</td> <td>   -2.110</td> <td> 0.035</td> <td>  -10.531</td> <td>   -0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Neg_E_interaction_term</th> <td>   -1.1580</td> <td>    1.886</td> <td>   -0.614</td> <td> 0.539</td> <td>   -4.854</td> <td>    2.538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EPS</th>                    <td>   -0.0626</td> <td>    0.001</td> <td>  -51.030</td> <td> 0.000</td> <td>   -0.065</td> <td>   -0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>              <td>    4.9093</td> <td>    1.672</td> <td>    2.937</td> <td> 0.003</td> <td>    1.633</td> <td>    8.185</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>227502.160</td> <th>  Durbin-Watson:     </th>     <td>   1.993</td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>2420571865593.842</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td>177.350</td>  <th>  Prob(JB):          </th>     <td>    0.00</td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>34739.008</td> <th>  Cond. No.          </th>     <td>2.40e+03</td>     \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.4e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             E_t1_EP_RI   R-squared:                       0.051\n",
       "Model:                            OLS   Adj. R-squared:                  0.051\n",
       "Method:                 Least Squares   F-statistic:                     870.1\n",
       "Date:                Sat, 06 May 2023   Prob (F-statistic):               0.00\n",
       "Time:                        18:49:41   Log-Likelihood:            -3.3664e+05\n",
       "No. Observations:               48142   AIC:                         6.733e+05\n",
       "Df Residuals:                   48138   BIC:                         6.733e+05\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "dummy_Neg_E_t             -5.4602      2.587     -2.110      0.035     -10.531      -0.389\n",
       "Neg_E_interaction_term    -1.1580      1.886     -0.614      0.539      -4.854       2.538\n",
       "EPS                       -0.0626      0.001    -51.030      0.000      -0.065      -0.060\n",
       "intercept                  4.9093      1.672      2.937      0.003       1.633       8.185\n",
       "==============================================================================\n",
       "Omnibus:                   227502.160   Durbin-Watson:                   1.993\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):    2420571865593.842\n",
       "Skew:                         177.350   Prob(JB):                         0.00\n",
       "Kurtosis:                   34739.008   Cond. No.                     2.40e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.4e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep_train_t1 = train_data[['dummy_Neg_E_t','Neg_E_interaction_term','EPS','E_t1_EP_RI']].dropna()\n",
    "\n",
    "# Estimate coefficients for HVZ Model at industry and fyear level\n",
    "ep_model_t1 = ols(ep_train_t1,'E_t1_EP_RI',['dummy_Neg_E_t','Neg_E_interaction_term','EPS'])\n",
    "params_ep_model_t1 = ep_model_t1.params\n",
    "ep_model_t1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6c01c833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for 2020: 295.23532015775567\n",
      "MSE for 2020: 861015.1679997757\n",
      "RMSE for 2020: 927.9090300238357\n",
      "Mean bias: -200.68666330344473\n",
      "Median bias: 1.1771928998407724\n",
      "p-value for mean bias: 3.477584868901503e-52\n",
      "p-value for median bias: 9.172985969485354e-53\n",
      "Mean accuracy: 1.1946360443241164\n",
      "Median accuracy: 1.6770041852323767\n",
      "p-value for mean accuracy: 0.5033637517255101\n",
      "p-value for median accuracy: 0.09725647919764034\n",
      "t-statistic: -15.385774169189597\n",
      "p-value for t-statistic: 3.477584868901503e-52\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "# Select the same columns as used in training the model\n",
    "ep_test_t1 = test_data_2019[['gvkey','dummy_Neg_E_t','Neg_E_interaction_term','EPS','E_t1_EP_RI']].dropna()\n",
    "ep_test_t1 = ep_test_t1.set_index('gvkey')\n",
    "\n",
    "# Make predictions using the model for 2022 test data\n",
    "y_pred_2020 = ep_test_t1.apply(lambda row: params_ep_model_t1['intercept'] + \\\n",
    "    params_ep_model_t1['dummy_Neg_E_t']*row['dummy_Neg_E_t'] + params_ep_model_t1['Neg_E_interaction_term']*\n",
    "                          row['Neg_E_interaction_term'] + \\\n",
    "    params_ep_model_t1['EPS']*row['EPS'] , axis=1)\n",
    "\n",
    "\n",
    "# Reset the index of the y_pred_2020 DataFrame\n",
    "y_pred_2020 = y_pred_2020.reset_index()\n",
    "\n",
    "y_true_2020 = test_data_2020[['gvkey', 'E_t']]\n",
    "merged_df = y_true_2020.merge(y_pred_2020, on='gvkey')\n",
    "\n",
    "# Rename the predicted column\n",
    "merged_df = merged_df.rename(columns={0: 'predicted'})\n",
    "\n",
    "# Calculate accuracy for 2020\n",
    "mae_2020 = mean_absolute_error(merged_df['E_t'], merged_df['predicted'])\n",
    "mse_2020 = mean_squared_error(merged_df['E_t'], merged_df['predicted'])\n",
    "rmse_2020 = mean_squared_error(merged_df['E_t'], merged_df['predicted'], squared=False)\n",
    "\n",
    "print(\"MAE for 2020:\", mae_2020)\n",
    "print(\"MSE for 2020:\", mse_2020)\n",
    "print(\"RMSE for 2020:\", rmse_2020)\n",
    "\n",
    "# Calculate bias and accuracy\n",
    "y_true = merged_df['E_t']\n",
    "y_pred = merged_df['predicted']\n",
    "bias = y_pred - y_true\n",
    "accuracy = 1 - abs(bias) / (y_true + 1e-9)\n",
    "\n",
    "# Compute mean and median of bias and accuracy\n",
    "bias_mean = bias.mean()\n",
    "bias_median = bias.median()\n",
    "accuracy_mean = accuracy.mean()\n",
    "accuracy_median = accuracy.median()\n",
    "\n",
    "# Compute p-values for mean and median bias and accuracy\n",
    "_, pval_bias_mean = ttest_1samp(bias, 0)\n",
    "_, pval_bias_median = ttest_1samp(bias, bias_median)\n",
    "_, pval_accuracy_mean = ttest_1samp(accuracy, 1)\n",
    "_, pval_accuracy_median = ttest_1samp(accuracy, accuracy_median)\n",
    "\n",
    "# Compute t-statistic\n",
    "t_statistic, p_value = ttest_rel(y_pred, y_true)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean bias: {bias_mean}\")\n",
    "print(f\"Median bias: {bias_median}\")\n",
    "print(f\"p-value for mean bias: {pval_bias_mean}\")\n",
    "print(f\"p-value for median bias: {pval_bias_median}\")\n",
    "print(f\"Mean accuracy: {accuracy_mean}\")\n",
    "print(f\"Median accuracy: {accuracy_median}\")\n",
    "print(f\"p-value for mean accuracy: {pval_accuracy_mean}\")\n",
    "print(f\"p-value for median accuracy: {pval_accuracy_median}\")\n",
    "print(f\"t-statistic: {t_statistic}\")\n",
    "print(f\"p-value for t-statistic: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948c29ae",
   "metadata": {},
   "source": [
    "#### EP model for earnings in year E_t+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "675c7016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>E_t2_EP_RI</td>    <th>  R-squared:         </th>  <td>   0.612</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.612</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>2.320e+04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 May 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:55:07</td>     <th>  Log-Likelihood:    </th> <td>-3.7320e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 44116</td>      <th>  AIC:               </th>  <td>7.464e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 44112</td>      <th>  BIC:               </th>  <td>7.464e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dummy_Neg_E_t</th>          <td>   -6.9388</td> <td>   11.759</td> <td>   -0.590</td> <td> 0.555</td> <td>  -29.986</td> <td>   16.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Neg_E_interaction_term</th> <td>    7.0852</td> <td>    8.747</td> <td>    0.810</td> <td> 0.418</td> <td>  -10.059</td> <td>   24.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EPS</th>                    <td>   -1.4030</td> <td>    0.005</td> <td> -263.760</td> <td> 0.000</td> <td>   -1.413</td> <td>   -1.393</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>              <td>    9.4540</td> <td>    7.485</td> <td>    1.263</td> <td> 0.207</td> <td>   -5.217</td> <td>   24.125</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>87905.342</td> <th>  Durbin-Watson:     </th>     <td>   1.999</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>744931879219.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>13.780</td>   <th>  Prob(JB):          </th>     <td>    0.00</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20134.004</td> <th>  Cond. No.          </th>     <td>2.51e+03</td>    \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.51e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             E_t2_EP_RI   R-squared:                       0.612\n",
       "Model:                            OLS   Adj. R-squared:                  0.612\n",
       "Method:                 Least Squares   F-statistic:                 2.320e+04\n",
       "Date:                Sat, 06 May 2023   Prob (F-statistic):               0.00\n",
       "Time:                        18:55:07   Log-Likelihood:            -3.7320e+05\n",
       "No. Observations:               44116   AIC:                         7.464e+05\n",
       "Df Residuals:                   44112   BIC:                         7.464e+05\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "dummy_Neg_E_t             -6.9388     11.759     -0.590      0.555     -29.986      16.109\n",
       "Neg_E_interaction_term     7.0852      8.747      0.810      0.418     -10.059      24.230\n",
       "EPS                       -1.4030      0.005   -263.760      0.000      -1.413      -1.393\n",
       "intercept                  9.4540      7.485      1.263      0.207      -5.217      24.125\n",
       "==============================================================================\n",
       "Omnibus:                    87905.342   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):     744931879219.128\n",
       "Skew:                          13.780   Prob(JB):                         0.00\n",
       "Kurtosis:                   20134.004   Cond. No.                     2.51e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.51e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep_train_t2 = train_data[['dummy_Neg_E_t','Neg_E_interaction_term','EPS','E_t2_EP_RI']].dropna()\n",
    "\n",
    "# Estimate coefficients for HVZ Model at industry and fyear level\n",
    "ep_model_t2 = ols(ep_train_t2,'E_t2_EP_RI',['dummy_Neg_E_t','Neg_E_interaction_term','EPS'])\n",
    "params_ep_model_t2 = ep_model_t2.params\n",
    "ep_model_t2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "28233063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for 2021: 421.09210339326825\n",
      "MSE for 2021: 1818009.3094342707\n",
      "RMSE for 2021: 1348.3357554534666\n",
      "Mean bias: -367.6133715565165\n",
      "Median bias: 2.43719581950836\n",
      "p-value for mean bias: 1.3404978403174376e-77\n",
      "p-value for median bias: 1.4399836432002398e-78\n",
      "Mean accuracy: 1.7391316057708062\n",
      "Median accuracy: 0.8731841620020917\n",
      "p-value for mean accuracy: 0.40663593970011447\n",
      "p-value for median accuracy: 0.33095536751763865\n",
      "t-statistic: -19.01379457311935\n",
      "p-value for t-statistic: 1.3404978403174376e-77\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "# Select the same columns as used in training the model\n",
    "ep_test_t2 = test_data_2019[['gvkey','dummy_Neg_E_t','Neg_E_interaction_term','EPS','E_t2_EP_RI']].dropna()\n",
    "ep_test_t2 = ep_test_t2.set_index('gvkey')\n",
    "\n",
    "# Make predictions using the model for 2022 test data\n",
    "y_pred_2021 = ep_test_t2.apply(lambda row: params_ep_model_t2['intercept'] + \\\n",
    "    params_ep_model_t2['dummy_Neg_E_t']*row['dummy_Neg_E_t'] + params_ep_model_t2['Neg_E_interaction_term']*\n",
    "                          row['Neg_E_interaction_term'] + \\\n",
    "    params_ep_model_t2['EPS']*row['EPS'] , axis=1)\n",
    "\n",
    "\n",
    "# Reset the index of the y_pred_2021 DataFrame\n",
    "y_pred_2021 = y_pred_2021.reset_index()\n",
    "\n",
    "y_true_2021 = test_data_2021[['gvkey', 'E_t']]\n",
    "merged_df = y_true_2021.merge(y_pred_2021, on='gvkey')\n",
    "\n",
    "# Rename the predicted column\n",
    "merged_df = merged_df.rename(columns={0: 'predicted'})\n",
    "\n",
    "# Calculate accuracy for 2021\n",
    "mae_2021 = mean_absolute_error(merged_df['E_t'], merged_df['predicted'])\n",
    "mse_2021 = mean_squared_error(merged_df['E_t'], merged_df['predicted'])\n",
    "rmse_2021 = mean_squared_error(merged_df['E_t'], merged_df['predicted'], squared=False)\n",
    "\n",
    "print(\"MAE for 2021:\", mae_2021)\n",
    "print(\"MSE for 2021:\", mse_2021)\n",
    "print(\"RMSE for 2021:\", rmse_2021)\n",
    "\n",
    "# Calculate bias and accuracy\n",
    "y_true = merged_df['E_t']\n",
    "y_pred = merged_df['predicted']\n",
    "bias = y_pred - y_true\n",
    "accuracy = 1 - abs(bias) / (y_true + 1e-9)\n",
    "\n",
    "# Compute mean and median of bias and accuracy\n",
    "bias_mean = bias.mean()\n",
    "bias_median = bias.median()\n",
    "accuracy_mean = accuracy.mean()\n",
    "accuracy_median = accuracy.median()\n",
    "\n",
    "# Compute p-values for mean and median bias and accuracy\n",
    "_, pval_bias_mean = ttest_1samp(bias, 0)\n",
    "_, pval_bias_median = ttest_1samp(bias, bias_median)\n",
    "_, pval_accuracy_mean = ttest_1samp(accuracy, 1)\n",
    "_, pval_accuracy_median = ttest_1samp(accuracy, accuracy_median)\n",
    "\n",
    "# Compute t-statistic\n",
    "t_statistic, p_value = ttest_rel(y_pred, y_true)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean bias: {bias_mean}\")\n",
    "print(f\"Median bias: {bias_median}\")\n",
    "print(f\"p-value for mean bias: {pval_bias_mean}\")\n",
    "print(f\"p-value for median bias: {pval_bias_median}\")\n",
    "print(f\"Mean accuracy: {accuracy_mean}\")\n",
    "print(f\"Median accuracy: {accuracy_median}\")\n",
    "print(f\"p-value for mean accuracy: {pval_accuracy_mean}\")\n",
    "print(f\"p-value for median accuracy: {pval_accuracy_median}\")\n",
    "print(f\"t-statistic: {t_statistic}\")\n",
    "print(f\"p-value for t-statistic: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4bec18",
   "metadata": {},
   "source": [
    "#### EP model for earnings in year E_t+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "eede32f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>E_t3_EP_RI</td>    <th>  R-squared:         </th>  <td>   0.483</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.483</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>1.262e+04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 May 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:58:47</td>     <th>  Log-Likelihood:    </th> <td>-3.6906e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 40535</td>      <th>  AIC:               </th>  <td>7.381e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 40531</td>      <th>  BIC:               </th>  <td>7.382e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dummy_Neg_E_t</th>          <td>   -8.2466</td> <td>   23.483</td> <td>   -0.351</td> <td> 0.725</td> <td>  -54.274</td> <td>   37.781</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Neg_E_interaction_term</th> <td>   12.1292</td> <td>   17.780</td> <td>    0.682</td> <td> 0.495</td> <td>  -22.720</td> <td>   46.978</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EPS</th>                    <td>   -1.9722</td> <td>    0.010</td> <td> -194.499</td> <td> 0.000</td> <td>   -1.992</td> <td>   -1.952</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>              <td>   13.3827</td> <td>   14.720</td> <td>    0.909</td> <td> 0.363</td> <td>  -15.469</td> <td>   42.234</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>71892.687</td> <th>  Durbin-Watson:     </th>     <td>   1.999</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>611441835820.766</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>10.297</td>   <th>  Prob(JB):          </th>     <td>    0.00</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>19029.892</td> <th>  Cond. No.          </th>     <td>2.63e+03</td>    \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.63e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             E_t3_EP_RI   R-squared:                       0.483\n",
       "Model:                            OLS   Adj. R-squared:                  0.483\n",
       "Method:                 Least Squares   F-statistic:                 1.262e+04\n",
       "Date:                Sat, 06 May 2023   Prob (F-statistic):               0.00\n",
       "Time:                        18:58:47   Log-Likelihood:            -3.6906e+05\n",
       "No. Observations:               40535   AIC:                         7.381e+05\n",
       "Df Residuals:                   40531   BIC:                         7.382e+05\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "dummy_Neg_E_t             -8.2466     23.483     -0.351      0.725     -54.274      37.781\n",
       "Neg_E_interaction_term    12.1292     17.780      0.682      0.495     -22.720      46.978\n",
       "EPS                       -1.9722      0.010   -194.499      0.000      -1.992      -1.952\n",
       "intercept                 13.3827     14.720      0.909      0.363     -15.469      42.234\n",
       "==============================================================================\n",
       "Omnibus:                    71892.687   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):     611441835820.766\n",
       "Skew:                          10.297   Prob(JB):                         0.00\n",
       "Kurtosis:                   19029.892   Cond. No.                     2.63e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.63e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep_train_t3 = train_data[['dummy_Neg_E_t','Neg_E_interaction_term','EPS','E_t3_EP_RI']].dropna()\n",
    "\n",
    "# Estimate coefficients for HVZ Model at industry and fyear level\n",
    "ep_model_t3 = ols(ep_train_t3,'E_t3_EP_RI',['dummy_Neg_E_t','Neg_E_interaction_term','EPS'])\n",
    "params_ep_model_t3 = ep_model_t3.params\n",
    "ep_model_t3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7a0cd09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for 2022: 524.2327423258337\n",
      "MSE for 2022: 2561296.5190807614\n",
      "RMSE for 2022: 1600.4051109268432\n",
      "Mean bias: -462.2586372168261\n",
      "Median bias: 0.5445984292695928\n",
      "p-value for mean bias: 3.5756259813859655e-65\n",
      "p-value for median bias: 2.5726075320509307e-65\n",
      "Mean accuracy: -2.756425962717368\n",
      "Median accuracy: 0.43693321723349027\n",
      "p-value for mean accuracy: 0.3798912425558185\n",
      "p-value for median accuracy: 0.45537329128563475\n",
      "t-statistic: -17.42809190447095\n",
      "p-value for t-statistic: 3.5756259813859655e-65\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "# Select the same columns as used in training the model\n",
    "ep_test_t3 = test_data_2019[['gvkey','dummy_Neg_E_t','Neg_E_interaction_term','EPS','E_t3_EP_RI']].dropna()\n",
    "ep_test_t3 = ep_test_t3.set_index('gvkey')\n",
    "\n",
    "# Make predictions using the model for 2022 test data\n",
    "y_pred_2022 = ep_test_t3.apply(lambda row: params_ep_model_t3['intercept'] + \\\n",
    "    params_ep_model_t3['dummy_Neg_E_t']*row['dummy_Neg_E_t'] + params_ep_model_t3['Neg_E_interaction_term']*\n",
    "                          row['Neg_E_interaction_term'] + \\\n",
    "    params_ep_model_t3['EPS']*row['EPS'] , axis=1)\n",
    "\n",
    "\n",
    "# Reset the index of the y_pred_2022 DataFrame\n",
    "y_pred_2022 = y_pred_2022.reset_index()\n",
    "\n",
    "y_true_2022 = test_data_2022[['gvkey', 'E_t']]\n",
    "merged_df = y_true_2022.merge(y_pred_2022, on='gvkey')\n",
    "\n",
    "# Rename the predicted column\n",
    "merged_df = merged_df.rename(columns={0: 'predicted'})\n",
    "\n",
    "# Calculate accuracy for 2022\n",
    "mae_2022 = mean_absolute_error(merged_df['E_t'], merged_df['predicted'])\n",
    "mse_2022 = mean_squared_error(merged_df['E_t'], merged_df['predicted'])\n",
    "rmse_2022 = mean_squared_error(merged_df['E_t'], merged_df['predicted'], squared=False)\n",
    "\n",
    "print(\"MAE for 2022:\", mae_2022)\n",
    "print(\"MSE for 2022:\", mse_2022)\n",
    "print(\"RMSE for 2022:\", rmse_2022)\n",
    "\n",
    "# Calculate bias and accuracy\n",
    "y_true = merged_df['E_t']\n",
    "y_pred = merged_df['predicted']\n",
    "bias = y_pred - y_true\n",
    "accuracy = 1 - abs(bias) / (y_true + 1e-9)\n",
    "\n",
    "# Compute mean and median of bias and accuracy\n",
    "bias_mean = bias.mean()\n",
    "bias_median = bias.median()\n",
    "accuracy_mean = accuracy.mean()\n",
    "accuracy_median = accuracy.median()\n",
    "\n",
    "# Compute p-values for mean and median bias and accuracy\n",
    "_, pval_bias_mean = ttest_1samp(bias, 0)\n",
    "_, pval_bias_median = ttest_1samp(bias, bias_median)\n",
    "_, pval_accuracy_mean = ttest_1samp(accuracy, 1)\n",
    "_, pval_accuracy_median = ttest_1samp(accuracy, accuracy_median)\n",
    "\n",
    "# Compute t-statistic\n",
    "t_statistic, p_value = ttest_rel(y_pred, y_true)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean bias: {bias_mean}\")\n",
    "print(f\"Median bias: {bias_median}\")\n",
    "print(f\"p-value for mean bias: {pval_bias_mean}\")\n",
    "print(f\"p-value for median bias: {pval_bias_median}\")\n",
    "print(f\"Mean accuracy: {accuracy_mean}\")\n",
    "print(f\"Median accuracy: {accuracy_median}\")\n",
    "print(f\"p-value for mean accuracy: {pval_accuracy_mean}\")\n",
    "print(f\"p-value for median accuracy: {pval_accuracy_median}\")\n",
    "print(f\"t-statistic: {t_statistic}\")\n",
    "print(f\"p-value for t-statistic: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7880296",
   "metadata": {},
   "source": [
    "## Residual Income Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4120a2",
   "metadata": {},
   "source": [
    "#### RI model for earnings in year E_t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6d5e315f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>E_t1_EP_RI</td>    <th>  R-squared:         </th>  <td>   0.002</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.002</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   21.40</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 May 2023</td> <th>  Prob (F-statistic):</th>  <td>1.18e-17</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:01:45</td>     <th>  Log-Likelihood:    </th> <td>-3.3787e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 48142</td>      <th>  AIC:               </th>  <td>6.757e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 48137</td>      <th>  BIC:               </th>  <td>6.758e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dummy_Neg_E_t</th>          <td>    6.7558</td> <td>    3.041</td> <td>    2.222</td> <td> 0.026</td> <td>    0.795</td> <td>   12.716</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Neg_E_interaction_term</th> <td>   -1.7362</td> <td>    1.960</td> <td>   -0.886</td> <td> 0.376</td> <td>   -5.578</td> <td>    2.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B_t</th>                    <td>    0.4533</td> <td>    0.377</td> <td>    1.201</td> <td> 0.230</td> <td>   -0.286</td> <td>    1.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TACC_t</th>                 <td>    0.7337</td> <td>    0.396</td> <td>    1.853</td> <td> 0.064</td> <td>   -0.042</td> <td>    1.510</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>              <td>   -8.7165</td> <td>    2.358</td> <td>   -3.696</td> <td> 0.000</td> <td>  -13.338</td> <td>   -4.095</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>223502.387</td> <th>  Durbin-Watson:     </th>     <td>   1.994</td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>1736923425898.895</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td>167.027</td>  <th>  Prob(JB):          </th>     <td>    0.00</td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>29427.284</td> <th>  Cond. No.          </th>     <td>    53.2</td>     \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             E_t1_EP_RI   R-squared:                       0.002\n",
       "Model:                            OLS   Adj. R-squared:                  0.002\n",
       "Method:                 Least Squares   F-statistic:                     21.40\n",
       "Date:                Sat, 06 May 2023   Prob (F-statistic):           1.18e-17\n",
       "Time:                        19:01:45   Log-Likelihood:            -3.3787e+05\n",
       "No. Observations:               48142   AIC:                         6.757e+05\n",
       "Df Residuals:                   48137   BIC:                         6.758e+05\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "dummy_Neg_E_t              6.7558      3.041      2.222      0.026       0.795      12.716\n",
       "Neg_E_interaction_term    -1.7362      1.960     -0.886      0.376      -5.578       2.105\n",
       "B_t                        0.4533      0.377      1.201      0.230      -0.286       1.193\n",
       "TACC_t                     0.7337      0.396      1.853      0.064      -0.042       1.510\n",
       "intercept                 -8.7165      2.358     -3.696      0.000     -13.338      -4.095\n",
       "==============================================================================\n",
       "Omnibus:                   223502.387   Durbin-Watson:                   1.994\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):    1736923425898.895\n",
       "Skew:                         167.027   Prob(JB):                         0.00\n",
       "Kurtosis:                   29427.284   Cond. No.                         53.2\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ri_train_t1 = train_data[['dummy_Neg_E_t','Neg_E_interaction_term','B_t','TACC_t','E_t1_EP_RI']].dropna()\n",
    "\n",
    "# Estimate coefficients for HVZ Model at industry and fyear level\n",
    "ri_model_t1 = ols(ri_train_t1,'E_t1_EP_RI',['dummy_Neg_E_t','Neg_E_interaction_term','B_t','TACC_t'])\n",
    "params_ri_model_t1 = ri_model_t1.params\n",
    "ri_model_t1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "505a9d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for 2020: 294.22782156147224\n",
      "MSE for 2020: 855418.7495544594\n",
      "RMSE for 2020: 924.8885065533356\n",
      "Mean bias: -198.27634614366502\n",
      "Median bias: -0.7830144558256233\n",
      "p-value for mean bias: 2.7781508722465745e-51\n",
      "p-value for median bias: 6.682443660692059e-51\n",
      "Mean accuracy: 0.7931386642552858\n",
      "Median accuracy: 1.4423164505642112\n",
      "p-value for mean accuracy: 0.7555694405794198\n",
      "p-value for median accuracy: 0.3286189118690286\n",
      "t-statistic: -15.244088922089777\n",
      "p-value for t-statistic: 2.7781508722465745e-51\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "# Select the same columns as used in training the model\n",
    "ri_test_t1 = test_data_2019[['gvkey','dummy_Neg_E_t','Neg_E_interaction_term','B_t','TACC_t','E_t1_EP_RI']].dropna()\n",
    "ri_test_t1 = ri_test_t1.set_index('gvkey')\n",
    "\n",
    "# Make predictions using the model\n",
    "y_pred_2020 = ri_test_t1.apply(lambda row: params_ri_model_t1['intercept'] + \\\n",
    "    params_ri_model_t1['dummy_Neg_E_t']*row['dummy_Neg_E_t'] + params_ri_model_t1['Neg_E_interaction_term']*\n",
    "                          row['Neg_E_interaction_term'] + \\\n",
    "    params_ri_model_t1['B_t']*row['B_t'] + \\\n",
    "    params_ri_model_t1['TACC_t']*row['TACC_t'] , axis=1)\n",
    "\n",
    "\n",
    "# Reset the index of the y_pred_2022 DataFrame\n",
    "y_pred_2020 = y_pred_2020.reset_index()\n",
    "\n",
    "y_true_2020 = test_data_2020[['gvkey', 'E_t']]\n",
    "merged_df = y_true_2020.merge(y_pred_2020, on='gvkey')\n",
    "\n",
    "# Rename the predicted column\n",
    "merged_df = merged_df.rename(columns={0: 'predicted'})\n",
    "\n",
    "# Calculate accuracy for 2020\n",
    "mae_2020 = mean_absolute_error(merged_df['E_t'], merged_df['predicted'])\n",
    "mse_2020 = mean_squared_error(merged_df['E_t'], merged_df['predicted'])\n",
    "rmse_2020 = mean_squared_error(merged_df['E_t'], merged_df['predicted'], squared=False)\n",
    "\n",
    "print(\"MAE for 2020:\", mae_2020)\n",
    "print(\"MSE for 2020:\", mse_2020)\n",
    "print(\"RMSE for 2020:\", rmse_2020)\n",
    "\n",
    "# Calculate bias and accuracy\n",
    "y_true = merged_df['E_t']\n",
    "y_pred = merged_df['predicted']\n",
    "bias = y_pred - y_true\n",
    "accuracy = 1 - abs(bias) / (y_true + 1e-9)\n",
    "\n",
    "# Compute mean and median of bias and accuracy\n",
    "bias_mean = bias.mean()\n",
    "bias_median = bias.median()\n",
    "accuracy_mean = accuracy.mean()\n",
    "accuracy_median = accuracy.median()\n",
    "\n",
    "# Compute p-values for mean and median bias and accuracy\n",
    "_, pval_bias_mean = ttest_1samp(bias, 0)\n",
    "_, pval_bias_median = ttest_1samp(bias, bias_median)\n",
    "_, pval_accuracy_mean = ttest_1samp(accuracy, 1)\n",
    "_, pval_accuracy_median = ttest_1samp(accuracy, accuracy_median)\n",
    "\n",
    "# Compute t-statistic\n",
    "t_statistic, p_value = ttest_rel(y_pred, y_true)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean bias: {bias_mean}\")\n",
    "print(f\"Median bias: {bias_median}\")\n",
    "print(f\"p-value for mean bias: {pval_bias_mean}\")\n",
    "print(f\"p-value for median bias: {pval_bias_median}\")\n",
    "print(f\"Mean accuracy: {accuracy_mean}\")\n",
    "print(f\"Median accuracy: {accuracy_median}\")\n",
    "print(f\"p-value for mean accuracy: {pval_accuracy_mean}\")\n",
    "print(f\"p-value for median accuracy: {pval_accuracy_median}\")\n",
    "print(f\"t-statistic: {t_statistic}\")\n",
    "print(f\"p-value for t-statistic: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ec0185",
   "metadata": {},
   "source": [
    "#### RI model for earnings in year E_t+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cd4ec778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>E_t2_EP_RI</td>    <th>  R-squared:         </th>  <td>   0.001</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.001</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   12.06</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 May 2023</td> <th>  Prob (F-statistic):</th>  <td>8.47e-10</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:06:00</td>     <th>  Log-Likelihood:    </th> <td>-3.9407e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 44116</td>      <th>  AIC:               </th>  <td>7.881e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 44111</td>      <th>  BIC:               </th>  <td>7.882e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dummy_Neg_E_t</th>          <td>   42.7213</td> <td>   21.623</td> <td>    1.976</td> <td> 0.048</td> <td>    0.341</td> <td>   85.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Neg_E_interaction_term</th> <td>  -47.9389</td> <td>   14.217</td> <td>   -3.372</td> <td> 0.001</td> <td>  -75.805</td> <td>  -20.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B_t</th>                    <td>    1.8022</td> <td>    2.674</td> <td>    0.674</td> <td> 0.500</td> <td>   -3.439</td> <td>    7.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TACC_t</th>                 <td>    3.3758</td> <td>    2.805</td> <td>    1.203</td> <td> 0.229</td> <td>   -2.123</td> <td>    8.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>              <td>  -55.3404</td> <td>   16.642</td> <td>   -3.325</td> <td> 0.001</td> <td>  -87.958</td> <td>  -22.722</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>216755.339</td> <th>  Durbin-Watson:     </th>     <td>   2.000</td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>3245045687980.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td>203.018</td>  <th>  Prob(JB):          </th>     <td>    0.00</td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>42017.353</td> <th>  Cond. No.          </th>     <td>    54.4</td>     \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             E_t2_EP_RI   R-squared:                       0.001\n",
       "Model:                            OLS   Adj. R-squared:                  0.001\n",
       "Method:                 Least Squares   F-statistic:                     12.06\n",
       "Date:                Sat, 06 May 2023   Prob (F-statistic):           8.47e-10\n",
       "Time:                        19:06:00   Log-Likelihood:            -3.9407e+05\n",
       "No. Observations:               44116   AIC:                         7.881e+05\n",
       "Df Residuals:                   44111   BIC:                         7.882e+05\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "dummy_Neg_E_t             42.7213     21.623      1.976      0.048       0.341      85.102\n",
       "Neg_E_interaction_term   -47.9389     14.217     -3.372      0.001     -75.805     -20.073\n",
       "B_t                        1.8022      2.674      0.674      0.500      -3.439       7.044\n",
       "TACC_t                     3.3758      2.805      1.203      0.229      -2.123       8.875\n",
       "intercept                -55.3404     16.642     -3.325      0.001     -87.958     -22.722\n",
       "==============================================================================\n",
       "Omnibus:                   216755.339   Durbin-Watson:                   2.000\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):    3245045687980.930\n",
       "Skew:                         203.018   Prob(JB):                         0.00\n",
       "Kurtosis:                   42017.353   Cond. No.                         54.4\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ri_train_t2 = train_data[['dummy_Neg_E_t','Neg_E_interaction_term','B_t','TACC_t','E_t2_EP_RI']].dropna()\n",
    "\n",
    "# Estimate coefficients for HVZ Model at industry and fyear level\n",
    "ri_model_t2 = ols(ri_train_t2,'E_t2_EP_RI',['dummy_Neg_E_t','Neg_E_interaction_term','B_t','TACC_t'])\n",
    "params_ri_model_t2 = ri_model_t2.params\n",
    "ri_model_t2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4072866f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for 2021: 433.77938678199183\n",
      "MSE for 2021: 1775516.3785760547\n",
      "RMSE for 2021: 1332.4850387813196\n",
      "Mean bias: -341.36490886900157\n",
      "Median bias: -10.808258092113311\n",
      "p-value for mean bias: 2.0027237785518484e-68\n",
      "p-value for median bias: 2.096175152511329e-64\n",
      "Mean accuracy: 4.0687597545757495\n",
      "Median accuracy: 0.8496381371489664\n",
      "p-value for mean accuracy: 0.5170994476980539\n",
      "p-value for median accuracy: 0.4967810992762579\n",
      "t-statistic: -17.782802718672016\n",
      "p-value for t-statistic: 2.0027237785518484e-68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "# Select the same columns as used in training the model\n",
    "ri_test_t2 = test_data_2019[['gvkey','dummy_Neg_E_t','Neg_E_interaction_term','B_t','TACC_t','E_t2_EP_RI']].dropna()\n",
    "ri_test_t2 = ri_test_t2.set_index('gvkey')\n",
    "\n",
    "# Make predictions using the model\n",
    "y_pred_2021 = ri_test_t2.apply(lambda row: params_ri_model_t2['intercept'] + \\\n",
    "    params_ri_model_t2['dummy_Neg_E_t']*row['dummy_Neg_E_t'] + params_ri_model_t2['Neg_E_interaction_term']*\n",
    "                          row['Neg_E_interaction_term'] + \\\n",
    "    params_ri_model_t2['B_t']*row['B_t'] + \\\n",
    "    params_ri_model_t2['TACC_t']*row['TACC_t'] , axis=1)\n",
    "\n",
    "\n",
    "# Reset the index of the y_pred_2022 DataFrame\n",
    "y_pred_2021 = y_pred_2021.reset_index()\n",
    "\n",
    "y_true_2021= test_data_2021[['gvkey', 'E_t']]\n",
    "merged_df = y_true_2021.merge(y_pred_2021, on='gvkey')\n",
    "\n",
    "# Rename the predicted column\n",
    "merged_df = merged_df.rename(columns={0: 'predicted'})\n",
    "\n",
    "# Calculate accuracy for 2021\n",
    "mae_2021 = mean_absolute_error(merged_df['E_t'], merged_df['predicted'])\n",
    "mse_2021 = mean_squared_error(merged_df['E_t'], merged_df['predicted'])\n",
    "rmse_2021 = mean_squared_error(merged_df['E_t'], merged_df['predicted'], squared=False)\n",
    "\n",
    "print(\"MAE for 2021:\", mae_2021)\n",
    "print(\"MSE for 2021:\", mse_2021)\n",
    "print(\"RMSE for 2021:\", rmse_2021)\n",
    "\n",
    "# Calculate bias and accuracy\n",
    "y_true = merged_df['E_t']\n",
    "y_pred = merged_df['predicted']\n",
    "bias = y_pred - y_true\n",
    "accuracy = 1 - abs(bias) / (y_true + 1e-9)\n",
    "\n",
    "# Compute mean and median of bias and accuracy\n",
    "bias_mean = bias.mean()\n",
    "bias_median = bias.median()\n",
    "accuracy_mean = accuracy.mean()\n",
    "accuracy_median = accuracy.median()\n",
    "\n",
    "# Compute p-values for mean and median bias and accuracy\n",
    "_, pval_bias_mean = ttest_1samp(bias, 0)\n",
    "_, pval_bias_median = ttest_1samp(bias, bias_median)\n",
    "_, pval_accuracy_mean = ttest_1samp(accuracy, 1)\n",
    "_, pval_accuracy_median = ttest_1samp(accuracy, accuracy_median)\n",
    "\n",
    "# Compute t-statistic\n",
    "t_statistic, p_value = ttest_rel(y_pred, y_true)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean bias: {bias_mean}\")\n",
    "print(f\"Median bias: {bias_median}\")\n",
    "print(f\"p-value for mean bias: {pval_bias_mean}\")\n",
    "print(f\"p-value for median bias: {pval_bias_median}\")\n",
    "print(f\"Mean accuracy: {accuracy_mean}\")\n",
    "print(f\"Median accuracy: {accuracy_median}\")\n",
    "print(f\"p-value for mean accuracy: {pval_accuracy_mean}\")\n",
    "print(f\"p-value for median accuracy: {pval_accuracy_median}\")\n",
    "print(f\"t-statistic: {t_statistic}\")\n",
    "print(f\"p-value for t-statistic: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa99afd9",
   "metadata": {},
   "source": [
    "#### RI model for earnings in year E_t+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b5ee9dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>E_t3_EP_RI</td>    <th>  R-squared:         </th>  <td>   0.001</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.001</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   9.202</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 May 2023</td> <th>  Prob (F-statistic):</th>  <td>1.99e-07</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:12:16</td>     <th>  Log-Likelihood:    </th> <td>-3.8241e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 40535</td>      <th>  AIC:               </th>  <td>7.648e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 40530</td>      <th>  BIC:               </th>  <td>7.649e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dummy_Neg_E_t</th>          <td>   64.3855</td> <td>   37.380</td> <td>    1.722</td> <td> 0.085</td> <td>   -8.880</td> <td>  137.651</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Neg_E_interaction_term</th> <td>  -75.1249</td> <td>   25.030</td> <td>   -3.001</td> <td> 0.003</td> <td> -124.184</td> <td>  -26.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B_t</th>                    <td>    2.7940</td> <td>    4.588</td> <td>    0.609</td> <td> 0.543</td> <td>   -6.198</td> <td>   11.786</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TACC_t</th>                 <td>    4.8003</td> <td>    4.817</td> <td>    0.997</td> <td> 0.319</td> <td>   -4.641</td> <td>   14.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>              <td>  -83.3170</td> <td>   28.529</td> <td>   -2.920</td> <td> 0.003</td> <td> -139.234</td> <td>  -27.400</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>198050.230</td> <th>  Durbin-Watson:     </th>     <td>   2.000</td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>2688593287810.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td>199.070</td>  <th>  Prob(JB):          </th>     <td>    0.00</td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>39899.194</td> <th>  Cond. No.          </th>     <td>    55.5</td>     \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             E_t3_EP_RI   R-squared:                       0.001\n",
       "Model:                            OLS   Adj. R-squared:                  0.001\n",
       "Method:                 Least Squares   F-statistic:                     9.202\n",
       "Date:                Sat, 06 May 2023   Prob (F-statistic):           1.99e-07\n",
       "Time:                        19:12:16   Log-Likelihood:            -3.8241e+05\n",
       "No. Observations:               40535   AIC:                         7.648e+05\n",
       "Df Residuals:                   40530   BIC:                         7.649e+05\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "dummy_Neg_E_t             64.3855     37.380      1.722      0.085      -8.880     137.651\n",
       "Neg_E_interaction_term   -75.1249     25.030     -3.001      0.003    -124.184     -26.066\n",
       "B_t                        2.7940      4.588      0.609      0.543      -6.198      11.786\n",
       "TACC_t                     4.8003      4.817      0.997      0.319      -4.641      14.242\n",
       "intercept                -83.3170     28.529     -2.920      0.003    -139.234     -27.400\n",
       "==============================================================================\n",
       "Omnibus:                   198050.230   Durbin-Watson:                   2.000\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):    2688593287810.559\n",
       "Skew:                         199.070   Prob(JB):                         0.00\n",
       "Kurtosis:                   39899.194   Cond. No.                         55.5\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ri_train_t3 = train_data[['dummy_Neg_E_t','Neg_E_interaction_term','B_t','TACC_t','E_t3_EP_RI']].dropna()\n",
    "\n",
    "# Estimate coefficients for HVZ Model at industry and fyear level\n",
    "ri_model_t3 = ols(ri_train_t3,'E_t3_EP_RI',['dummy_Neg_E_t','Neg_E_interaction_term','B_t','TACC_t'])\n",
    "params_ri_model_t3 = ri_model_t3.params\n",
    "ri_model_t3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bfc41655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for 2022: 544.6371003295816\n",
      "MSE for 2022: 2496224.0517631797\n",
      "RMSE for 2022: 1579.9443191970975\n",
      "Mean bias: -415.3672316693624\n",
      "Median bias: -16.710498936850897\n",
      "p-value for mean bias: 6.617141133965427e-54\n",
      "p-value for median bias: 6.2612782721511795e-50\n",
      "Mean accuracy: -26.09587845236394\n",
      "Median accuracy: 0.5735684813266599\n",
      "p-value for mean accuracy: 0.3076445222523254\n",
      "p-value for median accuracy: 0.3153188337491373\n",
      "t-statistic: -15.74058454532862\n",
      "p-value for t-statistic: 6.617141133965427e-54\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "# Select the same columns as used in training the model\n",
    "ri_test_t3 = test_data_2019[['gvkey','dummy_Neg_E_t','Neg_E_interaction_term','B_t','TACC_t','E_t3_EP_RI']].dropna()\n",
    "ri_test_t3 = ri_test_t3.set_index('gvkey')\n",
    "\n",
    "# Make predictions using the model\n",
    "y_pred_2022 = ri_test_t3.apply(lambda row: params_ri_model_t3['intercept'] + \\\n",
    "    params_ri_model_t3['dummy_Neg_E_t']*row['dummy_Neg_E_t'] + params_ri_model_t3['Neg_E_interaction_term']*\n",
    "                          row['Neg_E_interaction_term'] + \\\n",
    "    params_ri_model_t3['B_t']*row['B_t'] + \\\n",
    "    params_ri_model_t3['TACC_t']*row['TACC_t'] , axis=1)\n",
    "\n",
    "\n",
    "# Reset the index of the y_pred_2022 DataFrame\n",
    "y_pred_2022 = y_pred_2022.reset_index()\n",
    "\n",
    "y_true_2022= test_data_2022[['gvkey', 'E_t']]\n",
    "merged_df = y_true_2022.merge(y_pred_2022, on='gvkey')\n",
    "\n",
    "# Rename the predicted column\n",
    "merged_df = merged_df.rename(columns={0: 'predicted'})\n",
    "\n",
    "# Calculate accuracy for 2022\n",
    "mae_2022 = mean_absolute_error(merged_df['E_t'], merged_df['predicted'])\n",
    "mse_2022 = mean_squared_error(merged_df['E_t'], merged_df['predicted'])\n",
    "rmse_2022 = mean_squared_error(merged_df['E_t'], merged_df['predicted'], squared=False)\n",
    "\n",
    "print(\"MAE for 2022:\", mae_2022)\n",
    "print(\"MSE for 2022:\", mse_2022)\n",
    "print(\"RMSE for 2022:\", rmse_2022)\n",
    "\n",
    "# Calculate bias and accuracy\n",
    "y_true = merged_df['E_t']\n",
    "y_pred = merged_df['predicted']\n",
    "bias = y_pred - y_true\n",
    "accuracy = 1 - abs(bias) / (y_true + 1e-9)\n",
    "\n",
    "# Compute mean and median of bias and accuracy\n",
    "bias_mean = bias.mean()\n",
    "bias_median = bias.median()\n",
    "accuracy_mean = accuracy.mean()\n",
    "accuracy_median = accuracy.median()\n",
    "\n",
    "# Compute p-values for mean and median bias and accuracy\n",
    "_, pval_bias_mean = ttest_1samp(bias, 0)\n",
    "_, pval_bias_median = ttest_1samp(bias, bias_median)\n",
    "_, pval_accuracy_mean = ttest_1samp(accuracy, 1)\n",
    "_, pval_accuracy_median = ttest_1samp(accuracy, accuracy_median)\n",
    "\n",
    "# Compute t-statistic\n",
    "t_statistic, p_value = ttest_rel(y_pred, y_true)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean bias: {bias_mean}\")\n",
    "print(f\"Median bias: {bias_median}\")\n",
    "print(f\"p-value for mean bias: {pval_bias_mean}\")\n",
    "print(f\"p-value for median bias: {pval_bias_median}\")\n",
    "print(f\"Mean accuracy: {accuracy_mean}\")\n",
    "print(f\"Median accuracy: {accuracy_median}\")\n",
    "print(f\"p-value for mean accuracy: {pval_accuracy_mean}\")\n",
    "print(f\"p-value for median accuracy: {pval_accuracy_median}\")\n",
    "print(f\"t-statistic: {t_statistic}\")\n",
    "print(f\"p-value for t-statistic: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9edd66d",
   "metadata": {},
   "source": [
    "#### Based on the best model, I have further improved the model by considering additional factors. Additional factors can include the most recent analyst forecast (released prior to earnings), sales growth, return on assets, research and development expenses, financial ratios, and dividend payout ratio,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdf6785",
   "metadata": {},
   "source": [
    "Selected Best Model is HVZ for predicting earnings for 2020 and 2021. \n",
    "Selected Best Model is RI for predicting earnings for 2022.\n",
    "\n",
    "Now we will create these additional predictors to augment our original models in an attempt to improve our model forecast accruacy.\n",
    "\n",
    "#### Additional Predictors\n",
    "\n",
    "1. Total Debt, df['total_debt'] = df['dltt']+df['dlc']\n",
    "2. Dividend payout ratio, 'DVC/NI'\n",
    "3. Sales growth, df['SALE'] = (df['SALE'] - df['SALE'].shift(1)) / df['SALE'].shift(1)\n",
    "4. Return on assets, 'NI'/'AT'\n",
    "5. Debt-to-equity ratio, total_debt / 'LSE'\n",
    "6. Cash flow from operations, 'OANCF'\n",
    "7. Research and development expenses, 'RDIP'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f5aeae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = merged_data[['gvkey','tic','conm','invch','sic','prcc_f','fyear','cusip', 'industry',\n",
    "                      'dltt','dlc','dvc','ni','sale','at','lse','oancf','rdip']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "70b27bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to calculate new features within each group\n",
    "def cal_new_features(group):\n",
    "    group['total_debt'] = group['dltt']+group['dlc']\n",
    "    group['div_payout_ratio'] = group['dvc']/group['ni']\n",
    "    group['sale'] = (group['sale'] - group['sale'].shift(1))/group['sale'].shift(1)\n",
    "    group['roa'] = group['ni']/group['sale']\n",
    "    group['deq_ratio'] = group['total_debt']/group['lse']\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7bcf6efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\1339287206.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_new.fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill all remaining None Type values with zero\n",
    "df_new.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ef780d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to make sure that the data we use is for one company only and that it doesnot take values from a row above that belongs to some other company\n",
    "df_new = df_new.groupby('gvkey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "247c056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_df = df_new.apply(cal_new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0136d251",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = delta_df.merge(new_features_df, on=['tic','fyear'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1820730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {}\n",
    "for col in df_features.columns:\n",
    "    if col.endswith('_x'):\n",
    "        rename_dict[col] = col[:-2]\n",
    "# rename the columns\n",
    "df_features = df_features.rename(columns=rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4777a8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\2029543419.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = df_year[col].apply(lambda x: winsorize(x, limits=(0.01, 0.01)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\2029543419.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = df_year[col].apply(lambda x: winsorize(x, limits=(0.01, 0.01)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\2029543419.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = df_year[col].apply(lambda x: winsorize(x, limits=(0.01, 0.01)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\2029543419.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = df_year[col].apply(lambda x: winsorize(x, limits=(0.01, 0.01)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\2029543419.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = df_year[col].apply(lambda x: winsorize(x, limits=(0.01, 0.01)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\2029543419.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = df_year[col].apply(lambda x: winsorize(x, limits=(0.01, 0.01)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\2029543419.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = df_year[col].apply(lambda x: winsorize(x, limits=(0.01, 0.01)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\2029543419.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = df_year[col].apply(lambda x: winsorize(x, limits=(0.01, 0.01)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\2029543419.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = df_year[col].apply(lambda x: winsorize(x, limits=(0.01, 0.01)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\2029543419.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = df_year[col].apply(lambda x: winsorize(x, limits=(0.01, 0.01)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\2029543419.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = df_year[col].apply(lambda x: winsorize(x, limits=(0.01, 0.01)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\2029543419.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = df_year[col].apply(lambda x: winsorize(x, limits=(0.01, 0.01)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abbas\\AppData\\Local\\Temp\\ipykernel_32860\\2029543419.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_year[col] = df_year[col].apply(lambda x: winsorize(x, limits=(0.01, 0.01)))\n"
     ]
    }
   ],
   "source": [
    "# Create an empty data frame to hold the winsorized data\n",
    "df_win_new = pd.DataFrame()\n",
    "\n",
    "# List of columns to winsorize\n",
    "cols_to_winsorize = ['at','dvc','E_t','dummy_Neg_E_t','ACT','dltt','dlc','dvc','ni','sale',\n",
    "                     'lse','oancf','rdip','invch','E_t1_HVZ','E_t2_HVZ','E_t3_EP_RI','Neg_E_interaction_term','B_t','TACC_t',\n",
    "                     'div_payout_ratio','total_debt','deq_ratio','roa']\n",
    "\n",
    "# Winsorize by year\n",
    "for year in df_features['fyear'].unique():\n",
    "    # Subset the data for the current year\n",
    "    df_year = df_features[df_features['fyear'] == year]\n",
    "    print(df_year.shape[0])\n",
    "    # Winsorize the columns for the current year's data\n",
    "    for col in cols_to_winsorize:\n",
    "        #df_year[col].dropna(inplace=True)\n",
    "        #df_year[col] = winsorize(df_year[col], limits=(0.01, 0.01))\n",
    "        # Apply winsorize function to each column of the DataFrame\n",
    "        df_year[col] = df_year[col].apply(lambda x: winsorize(x, limits=(0.01, 0.01)))\n",
    "    \n",
    "    # Append the winsorized data for the current year to df_winsorized\n",
    "    df_win_new = pd.concat([df_win_new, df_year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d92e4b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>tic</th>\n",
       "      <th>conm</th>\n",
       "      <th>invch</th>\n",
       "      <th>sic</th>\n",
       "      <th>prcc_f</th>\n",
       "      <th>fyear</th>\n",
       "      <th>cusip</th>\n",
       "      <th>industry</th>\n",
       "      <th>ib</th>\n",
       "      <th>...</th>\n",
       "      <th>ni</th>\n",
       "      <th>sale</th>\n",
       "      <th>at_y</th>\n",
       "      <th>lse</th>\n",
       "      <th>oancf</th>\n",
       "      <th>rdip</th>\n",
       "      <th>total_debt</th>\n",
       "      <th>div_payout_ratio</th>\n",
       "      <th>roa</th>\n",
       "      <th>deq_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001004</td>\n",
       "      <td>AIR</td>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>-34.615</td>\n",
       "      <td>5080</td>\n",
       "      <td>26.390</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>000361105</td>\n",
       "      <td>50</td>\n",
       "      <td>73.139</td>\n",
       "      <td>...</td>\n",
       "      <td>69.826</td>\n",
       "      <td>0.313302</td>\n",
       "      <td>1703.727</td>\n",
       "      <td>1703.727</td>\n",
       "      <td>108.598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>443.877</td>\n",
       "      <td>0.042720</td>\n",
       "      <td>222.871546</td>\n",
       "      <td>0.260533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>001013</td>\n",
       "      <td>ADCT.1</td>\n",
       "      <td>ADC TELECOMMUNICATIONS INC</td>\n",
       "      <td>13.800</td>\n",
       "      <td>3661</td>\n",
       "      <td>12.670</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>000886309</td>\n",
       "      <td>36</td>\n",
       "      <td>77.200</td>\n",
       "      <td>...</td>\n",
       "      <td>62.000</td>\n",
       "      <td>0.160429</td>\n",
       "      <td>1474.500</td>\n",
       "      <td>1474.500</td>\n",
       "      <td>136.600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>651.100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>386.462789</td>\n",
       "      <td>0.441573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>001019</td>\n",
       "      <td>AFAP</td>\n",
       "      <td>AFA PROTECTIVE SYSTEMS INC</td>\n",
       "      <td>0.260</td>\n",
       "      <td>7380</td>\n",
       "      <td>240.000</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>001038108</td>\n",
       "      <td>73</td>\n",
       "      <td>0.997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997</td>\n",
       "      <td>-0.072240</td>\n",
       "      <td>29.546</td>\n",
       "      <td>29.546</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.653</td>\n",
       "      <td>7.993982</td>\n",
       "      <td>-13.801202</td>\n",
       "      <td>0.292865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>001045</td>\n",
       "      <td>AAL</td>\n",
       "      <td>AMERICAN AIRLINES GROUP INC</td>\n",
       "      <td>-81.000</td>\n",
       "      <td>4512</td>\n",
       "      <td>7.790</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>02376R102</td>\n",
       "      <td>45</td>\n",
       "      <td>-471.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-471.000</td>\n",
       "      <td>0.113119</td>\n",
       "      <td>25088.000</td>\n",
       "      <td>25088.000</td>\n",
       "      <td>1241.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11136.000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-4163.740346</td>\n",
       "      <td>0.443878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>001050</td>\n",
       "      <td>CECO</td>\n",
       "      <td>CECO ENVIRONMENTAL CORP</td>\n",
       "      <td>2.201</td>\n",
       "      <td>3564</td>\n",
       "      <td>5.960</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>125141101</td>\n",
       "      <td>35</td>\n",
       "      <td>2.305</td>\n",
       "      <td>...</td>\n",
       "      <td>2.105</td>\n",
       "      <td>0.011634</td>\n",
       "      <td>74.791</td>\n",
       "      <td>74.791</td>\n",
       "      <td>2.938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.929762</td>\n",
       "      <td>0.144402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73157</th>\n",
       "      <td>349972</td>\n",
       "      <td>INDP</td>\n",
       "      <td>INDAPTUS THERAPEUTICS INC</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2836</td>\n",
       "      <td>1.450</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>45339J105</td>\n",
       "      <td>28</td>\n",
       "      <td>-14.323</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.064</td>\n",
       "      <td>28.064</td>\n",
       "      <td>-13.078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73159</th>\n",
       "      <td>351038</td>\n",
       "      <td>QNRX</td>\n",
       "      <td>CELLECT BIOTECHNOLOGY LTD</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2834</td>\n",
       "      <td>1.420</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>74907L201</td>\n",
       "      <td>28</td>\n",
       "      <td>-9.381</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.458</td>\n",
       "      <td>14.458</td>\n",
       "      <td>-8.481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73160</th>\n",
       "      <td>351491</td>\n",
       "      <td>IVCGF</td>\n",
       "      <td>IVECO GROUP N V</td>\n",
       "      <td>-234.055</td>\n",
       "      <td>3711</td>\n",
       "      <td>5.880</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>N47017103</td>\n",
       "      <td>37</td>\n",
       "      <td>157.105</td>\n",
       "      <td>...</td>\n",
       "      <td>157.105</td>\n",
       "      <td>0.066417</td>\n",
       "      <td>17113.769</td>\n",
       "      <td>17113.769</td>\n",
       "      <td>1503.721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4737.734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2365.444075</td>\n",
       "      <td>0.276838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73162</th>\n",
       "      <td>351590</td>\n",
       "      <td>DTRUY</td>\n",
       "      <td>DAIMLER TRUCK HOLDING AG</td>\n",
       "      <td>-1221.573</td>\n",
       "      <td>3713</td>\n",
       "      <td>15.446</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>23384L101</td>\n",
       "      <td>37</td>\n",
       "      <td>2848.198</td>\n",
       "      <td>...</td>\n",
       "      <td>2848.198</td>\n",
       "      <td>0.201161</td>\n",
       "      <td>68366.372</td>\n",
       "      <td>68366.372</td>\n",
       "      <td>-558.952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22271.521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14158.828967</td>\n",
       "      <td>0.325767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73163</th>\n",
       "      <td>353444</td>\n",
       "      <td>HLN</td>\n",
       "      <td>HALEON PLC</td>\n",
       "      <td>-351.831</td>\n",
       "      <td>2834</td>\n",
       "      <td>8.000</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>405552100</td>\n",
       "      <td>28</td>\n",
       "      <td>1277.194</td>\n",
       "      <td>...</td>\n",
       "      <td>1277.194</td>\n",
       "      <td>0.012218</td>\n",
       "      <td>41948.594</td>\n",
       "      <td>41948.594</td>\n",
       "      <td>2485.709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12579.157</td>\n",
       "      <td>11.254717</td>\n",
       "      <td>104531.978880</td>\n",
       "      <td>0.299871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73164 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        gvkey     tic                         conm     invch   sic   prcc_f  \\\n",
       "0      001004     AIR                     AAR CORP   -34.615  5080   26.390   \n",
       "12     001013  ADCT.1   ADC TELECOMMUNICATIONS INC    13.800  3661   12.670   \n",
       "13     001019    AFAP   AFA PROTECTIVE SYSTEMS INC     0.260  7380  240.000   \n",
       "24     001045     AAL  AMERICAN AIRLINES GROUP INC   -81.000  4512    7.790   \n",
       "27     001050    CECO      CECO ENVIRONMENTAL CORP     2.201  3564    5.960   \n",
       "...       ...     ...                          ...       ...   ...      ...   \n",
       "73157  349972    INDP    INDAPTUS THERAPEUTICS INC     0.000  2836    1.450   \n",
       "73159  351038    QNRX    CELLECT BIOTECHNOLOGY LTD     0.000  2834    1.420   \n",
       "73160  351491   IVCGF              IVECO GROUP N V  -234.055  3711    5.880   \n",
       "73162  351590   DTRUY     DAIMLER TRUCK HOLDING AG -1221.573  3713   15.446   \n",
       "73163  353444     HLN                   HALEON PLC  -351.831  2834    8.000   \n",
       "\n",
       "        fyear      cusip  industry        ib  ...        ni      sale  \\\n",
       "0      2010.0  000361105        50    73.139  ...    69.826  0.313302   \n",
       "12     2010.0  000886309        36    77.200  ...    62.000  0.160429   \n",
       "13     2010.0  001038108        73     0.997  ...     0.997 -0.072240   \n",
       "24     2010.0  02376R102        45  -471.000  ...  -471.000  0.113119   \n",
       "27     2010.0  125141101        35     2.305  ...     2.105  0.011634   \n",
       "...       ...        ...       ...       ...  ...       ...       ...   \n",
       "73157  2022.0  45339J105        28   -14.323  ...   -14.323       NaN   \n",
       "73159  2022.0  74907L201        28    -9.381  ...    -9.381       NaN   \n",
       "73160  2022.0  N47017103        37   157.105  ...   157.105  0.066417   \n",
       "73162  2022.0  23384L101        37  2848.198  ...  2848.198  0.201161   \n",
       "73163  2022.0  405552100        28  1277.194  ...  1277.194  0.012218   \n",
       "\n",
       "            at_y        lse     oancf  rdip  total_debt  div_payout_ratio  \\\n",
       "0       1703.727   1703.727   108.598   0.0     443.877          0.042720   \n",
       "12      1474.500   1474.500   136.600   0.0     651.100          0.000000   \n",
       "13        29.546     29.546     0.829   0.0       8.653          7.993982   \n",
       "24     25088.000  25088.000  1241.000   0.0   11136.000         -0.000000   \n",
       "27        74.791     74.791     2.938   0.0      10.800          0.000000   \n",
       "...          ...        ...       ...   ...         ...               ...   \n",
       "73157     28.064     28.064   -13.078   0.0       0.080         -0.000000   \n",
       "73159     14.458     14.458    -8.481   0.0       0.000         -0.000000   \n",
       "73160  17113.769  17113.769  1503.721   0.0    4737.734          0.000000   \n",
       "73162  68366.372  68366.372  -558.952   0.0   22271.521          0.000000   \n",
       "73163  41948.594  41948.594  2485.709   0.0   12579.157         11.254717   \n",
       "\n",
       "                 roa  deq_ratio  \n",
       "0         222.871546   0.260533  \n",
       "12        386.462789   0.441573  \n",
       "13        -13.801202   0.292865  \n",
       "24      -4163.740346   0.443878  \n",
       "27        180.929762   0.144402  \n",
       "...              ...        ...  \n",
       "73157            NaN   0.002851  \n",
       "73159            NaN   0.000000  \n",
       "73160    2365.444075   0.276838  \n",
       "73162   14158.828967   0.325767  \n",
       "73163  104531.978880   0.299871  \n",
       "\n",
       "[73164 rows x 68 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_win_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ca5b17e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset = 2010-2019 Test dataset = 2020, 2021, and 2022\n",
    "# split data into training and test datasets based on date\n",
    "train_data_new = df_win_new[(df_win_new['fyear'] >= 2010) & (df_win_new['fyear'] <= 2018)]\n",
    "test_data_new = df_win_new[df_win_new['fyear'].isin([2019,2020, 2021, 2022])]\n",
    "test_data_new_2019 = df_win_new[df_win_new['fyear'] == 2019]\n",
    "test_data_new_2020 = df_win_new[df_win_new['fyear'] == 2020]\n",
    "test_data_new_2021 = df_win_new[df_win_new['fyear'] == 2021]\n",
    "test_data_new_2022 = df_win_new[df_win_new['fyear'] == 2022]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647cd866",
   "metadata": {},
   "source": [
    "#### Modified Model for Year 2020 with new features using HVZ model selected in Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "83b60c11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>E_t1_HVZ</td>     <th>  R-squared:         </th>  <td>   0.830</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.830</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>1.236e+04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 May 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:44:43</td>     <th>  Log-Likelihood:    </th> <td>-2.6291e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 32964</td>      <th>  AIC:               </th>  <td>5.258e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 32950</td>      <th>  BIC:               </th>  <td>5.260e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>at</th>               <td>   -0.0026</td> <td>    0.001</td> <td>   -4.244</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dvc</th>              <td>    0.0461</td> <td>    0.008</td> <td>    5.852</td> <td> 0.000</td> <td>    0.031</td> <td>    0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>E_t</th>              <td>    0.6155</td> <td>    0.006</td> <td>  105.912</td> <td> 0.000</td> <td>    0.604</td> <td>    0.627</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dummy_Neg_E_t</th>    <td>   -4.8699</td> <td>    8.151</td> <td>   -0.597</td> <td> 0.550</td> <td>  -20.847</td> <td>   11.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACT</th>              <td>    0.1626</td> <td>    0.006</td> <td>   26.873</td> <td> 0.000</td> <td>    0.151</td> <td>    0.174</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>div_payout_ratio</th> <td>    0.1124</td> <td>    0.432</td> <td>    0.260</td> <td> 0.795</td> <td>   -0.734</td> <td>    0.959</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_debt</th>       <td>    0.0192</td> <td>    0.001</td> <td>   15.198</td> <td> 0.000</td> <td>    0.017</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>deq_ratio</th>        <td>   -0.0356</td> <td>    0.282</td> <td>   -0.126</td> <td> 0.900</td> <td>   -0.589</td> <td>    0.518</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roa</th>              <td>-3.041e-05</td> <td> 6.64e-06</td> <td>   -4.579</td> <td> 0.000</td> <td>-4.34e-05</td> <td>-1.74e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>oancf</th>            <td>    0.2233</td> <td>    0.005</td> <td>   46.147</td> <td> 0.000</td> <td>    0.214</td> <td>    0.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rdip</th>             <td>   -0.3787</td> <td>    0.085</td> <td>   -4.453</td> <td> 0.000</td> <td>   -0.545</td> <td>   -0.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>invch</th>            <td>   -0.2633</td> <td>    0.015</td> <td>  -17.844</td> <td> 0.000</td> <td>   -0.292</td> <td>   -0.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sale</th>             <td>   -0.0046</td> <td>    0.042</td> <td>   -0.109</td> <td> 0.913</td> <td>   -0.088</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>        <td>    9.0840</td> <td>    5.164</td> <td>    1.759</td> <td> 0.079</td> <td>   -1.039</td> <td>   19.207</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>17735.712</td> <th>  Durbin-Watson:     </th>   <td>   1.984</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>123644356.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.725</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>303.032</td>  <th>  Cond. No.          </th>   <td>1.36e+06</td>   \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.36e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               E_t1_HVZ   R-squared:                       0.830\n",
       "Model:                            OLS   Adj. R-squared:                  0.830\n",
       "Method:                 Least Squares   F-statistic:                 1.236e+04\n",
       "Date:                Sat, 06 May 2023   Prob (F-statistic):               0.00\n",
       "Time:                        19:44:43   Log-Likelihood:            -2.6291e+05\n",
       "No. Observations:               32964   AIC:                         5.258e+05\n",
       "Df Residuals:                   32950   BIC:                         5.260e+05\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "at                  -0.0026      0.001     -4.244      0.000      -0.004      -0.001\n",
       "dvc                  0.0461      0.008      5.852      0.000       0.031       0.061\n",
       "E_t                  0.6155      0.006    105.912      0.000       0.604       0.627\n",
       "dummy_Neg_E_t       -4.8699      8.151     -0.597      0.550     -20.847      11.107\n",
       "ACT                  0.1626      0.006     26.873      0.000       0.151       0.174\n",
       "div_payout_ratio     0.1124      0.432      0.260      0.795      -0.734       0.959\n",
       "total_debt           0.0192      0.001     15.198      0.000       0.017       0.022\n",
       "deq_ratio           -0.0356      0.282     -0.126      0.900      -0.589       0.518\n",
       "roa              -3.041e-05   6.64e-06     -4.579      0.000   -4.34e-05   -1.74e-05\n",
       "oancf                0.2233      0.005     46.147      0.000       0.214       0.233\n",
       "rdip                -0.3787      0.085     -4.453      0.000      -0.545      -0.212\n",
       "invch               -0.2633      0.015    -17.844      0.000      -0.292      -0.234\n",
       "sale                -0.0046      0.042     -0.109      0.913      -0.088       0.078\n",
       "intercept            9.0840      5.164      1.759      0.079      -1.039      19.207\n",
       "==============================================================================\n",
       "Omnibus:                    17735.712   Durbin-Watson:                   1.984\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        123644356.023\n",
       "Skew:                          -0.725   Prob(JB):                         0.00\n",
       "Kurtosis:                     303.032   Cond. No.                     1.36e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.36e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with infinite values\n",
    "cols_to_check_for_inf = ['at','dvc','E_t','dummy_Neg_E_t','ACT','div_payout_ratio',\n",
    "                                                 'total_debt','deq_ratio','roa','oancf','rdip','invch','sale','E_t1_HVZ']\n",
    "hvz_train_new_t1 = train_data_new[cols_to_check_for_inf].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "hvz_train_new_t1 = hvz_train_new_t1.dropna(subset=['at','dvc','E_t','dummy_Neg_E_t','ACT','div_payout_ratio',\n",
    "                                                 'total_debt','deq_ratio','roa','oancf','rdip','invch','sale','E_t1_HVZ'])\n",
    "\n",
    "\n",
    "# Estimate coefficients for HVZ Model at industry and fyear level\n",
    "hvz_model_new_t1 = ols(hvz_train_new_t1,'E_t1_HVZ',['at','dvc','E_t','dummy_Neg_E_t','ACT','div_payout_ratio',\n",
    "                                                 'total_debt','deq_ratio','roa','oancf','rdip','invch','sale'])\n",
    "params_hvz_model_new_t1 = hvz_model_new_t1.params\n",
    "hvz_model_new_t1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a378e06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for 2020: 274.0529878040788\n",
      "MSE for 2020: 1944398.1433454952\n",
      "RMSE for 2020: 1394.4167753385268\n",
      "Mean bias: 98.9650596558048\n",
      "Median bias: 8.683123700096889\n",
      "p-value for mean bias: 1.1574534767716017e-05\n",
      "p-value for median bias: 6.293644048016392e-05\n",
      "Mean accuracy: 1.473281105558993\n",
      "Median accuracy: 0.9534771924018002\n",
      "p-value for mean accuracy: 0.5850816817413258\n",
      "p-value for median accuracy: 0.5487439250773191\n",
      "t-statistic: 4.39128202090691\n",
      "p-value for t-statistic: 1.1574534767716017e-05\n"
     ]
    }
   ],
   "source": [
    "# Testing Accuracy on out of sample data\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import ttest_1samp\n",
    "# Select the same columns as used in training the model\n",
    "# Remove rows with infinite values\n",
    "hvz_test_new_t1 = test_data_new_2019[cols_to_check_for_inf+['gvkey']].replace([np.inf, -np.inf], np.nan)\n",
    "hvz_test_new_t1 = hvz_test_new_t1.dropna(subset=cols_to_check_for_inf)\n",
    "hvz_test_new_t1 = hvz_test_new_t1.set_index('gvkey')\n",
    "\n",
    "\n",
    "# Make predictions using the model for 2020 test data\n",
    "y_pred_2020_new = hvz_test_new_t1.apply(lambda row: params_hvz_model_new_t1['intercept'] + \\\n",
    "    params_hvz_model_new_t1['at']*row['at'] + params_hvz_model_new_t1['dvc']*row['dvc'] + \\\n",
    "    params_hvz_model_new_t1['E_t']*row['E_t'] + params_hvz_model_new_t1['dummy_Neg_E_t']*row['dummy_Neg_E_t'] + \\\n",
    "    params_hvz_model_new_t1['ACT']*row['ACT'] + params_hvz_model_new_t1['div_payout_ratio']*row['div_payout_ratio'] + \\\n",
    "    params_hvz_model_new_t1['total_debt']*row['total_debt'] + params_hvz_model_new_t1['deq_ratio']*row['deq_ratio'] + \\\n",
    "    params_hvz_model_new_t1['roa']*row['roa'] + params_hvz_model_new_t1['oancf']*row['oancf'] + \\\n",
    "    params_hvz_model_new_t1['rdip']*row['rdip'] + params_hvz_model_new_t1['invch']*row['invch'] + \\\n",
    "    params_hvz_model_new_t1['sale']*row['sale'], axis=1)\n",
    "\n",
    "# Reset the index of the y_pred_2020 DataFrame\n",
    "y_pred_2020_new= y_pred_2020_new.reset_index()\n",
    "y_pred_2020_new\n",
    "y_true_2020_new = test_data_new_2020[['gvkey', 'E_t']]\n",
    "merged_df = y_true_2020_new.merge(y_pred_2020_new, on='gvkey')\n",
    "# Rename the predicted column\n",
    "merged_df = merged_df.rename(columns={0: 'predicted'})\n",
    "\n",
    "# Calculate accuracy for 2020\n",
    "mae_2020 = mean_absolute_error(merged_df['E_t'], merged_df['predicted'])\n",
    "mse_2020 = mean_squared_error(merged_df['E_t'], merged_df['predicted'])\n",
    "rmse_2020 = mean_squared_error(merged_df['E_t'], merged_df['predicted'], squared=False)\n",
    "\n",
    "print(\"MAE for 2020:\", mae_2020)\n",
    "print(\"MSE for 2020:\", mse_2020)\n",
    "print(\"RMSE for 2020:\", rmse_2020)\n",
    "\n",
    "# Calculate bias and accuracy\n",
    "y_true = merged_df['E_t']\n",
    "y_pred = merged_df['predicted']\n",
    "bias = y_pred - y_true\n",
    "accuracy = 1 - abs(bias) / (y_true + 1e-9)\n",
    "\n",
    "# Compute mean and median of bias and accuracy\n",
    "bias_mean = bias.mean()\n",
    "bias_median = bias.median()\n",
    "accuracy_mean = accuracy.mean()\n",
    "accuracy_median = accuracy.median()\n",
    "from scipy.stats import ttest_rel\n",
    "# Compute p-values for mean and median bias and accuracy\n",
    "_, pval_bias_mean = ttest_1samp(bias, 0)\n",
    "_, pval_bias_median = ttest_1samp(bias, bias_median)\n",
    "_, pval_accuracy_mean = ttest_1samp(accuracy, 1)\n",
    "_, pval_accuracy_median = ttest_1samp(accuracy, accuracy_median)\n",
    "\n",
    "# Compute t-statistic\n",
    "t_statistic, p_value = ttest_rel(y_pred, y_true)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean bias: {bias_mean}\")\n",
    "print(f\"Median bias: {bias_median}\")\n",
    "print(f\"p-value for mean bias: {pval_bias_mean}\")\n",
    "print(f\"p-value for median bias: {pval_bias_median}\")\n",
    "print(f\"Mean accuracy: {accuracy_mean}\")\n",
    "print(f\"Median accuracy: {accuracy_median}\")\n",
    "print(f\"p-value for mean accuracy: {pval_accuracy_mean}\")\n",
    "print(f\"p-value for median accuracy: {pval_accuracy_median}\")\n",
    "print(f\"t-statistic: {t_statistic}\")\n",
    "print(f\"p-value for t-statistic: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a884b407",
   "metadata": {},
   "source": [
    "#### Modified Model for Year 2021 to predict for 2021 earnings with new features using HVZ model selected in Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c5fc953d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>E_t2_HVZ</td>     <th>  R-squared:         </th>  <td>   0.679</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.678</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   4934.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 May 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:00:41</td>     <th>  Log-Likelihood:    </th> <td>-2.5364e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 30391</td>      <th>  AIC:               </th>  <td>5.073e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 30377</td>      <th>  BIC:               </th>  <td>5.074e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>at</th>               <td>   -0.0138</td> <td>    0.001</td> <td>  -15.266</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dvc</th>              <td>    0.0290</td> <td>    0.011</td> <td>    2.532</td> <td> 0.011</td> <td>    0.007</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>E_t</th>              <td>    0.4412</td> <td>    0.008</td> <td>   52.199</td> <td> 0.000</td> <td>    0.425</td> <td>    0.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dummy_Neg_E_t</th>    <td>  -17.6157</td> <td>   12.378</td> <td>   -1.423</td> <td> 0.155</td> <td>  -41.878</td> <td>    6.647</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACT</th>              <td>    0.2255</td> <td>    0.009</td> <td>   25.604</td> <td> 0.000</td> <td>    0.208</td> <td>    0.243</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>div_payout_ratio</th> <td>    0.3111</td> <td>    0.648</td> <td>    0.480</td> <td> 0.631</td> <td>   -0.960</td> <td>    1.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_debt</th>       <td>    0.0498</td> <td>    0.002</td> <td>   27.028</td> <td> 0.000</td> <td>    0.046</td> <td>    0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>deq_ratio</th>        <td>   -0.0844</td> <td>    0.465</td> <td>   -0.182</td> <td> 0.856</td> <td>   -0.995</td> <td>    0.826</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roa</th>              <td>-5.185e-05</td> <td> 9.62e-06</td> <td>   -5.390</td> <td> 0.000</td> <td>-7.07e-05</td> <td> -3.3e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>oancf</th>            <td>    0.3405</td> <td>    0.007</td> <td>   48.389</td> <td> 0.000</td> <td>    0.327</td> <td>    0.354</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rdip</th>             <td>   -1.1376</td> <td>    0.126</td> <td>   -9.012</td> <td> 0.000</td> <td>   -1.385</td> <td>   -0.890</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>invch</th>            <td>   -0.3023</td> <td>    0.022</td> <td>  -13.897</td> <td> 0.000</td> <td>   -0.345</td> <td>   -0.260</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sale</th>             <td>   -0.0101</td> <td>    0.062</td> <td>   -0.164</td> <td> 0.870</td> <td>   -0.131</td> <td>    0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>        <td>   32.2529</td> <td>    7.715</td> <td>    4.180</td> <td> 0.000</td> <td>   17.131</td> <td>   47.375</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>35448.761</td> <th>  Durbin-Watson:     </th>   <td>   1.961</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>114743648.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-4.978</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>303.857</td>  <th>  Cond. No.          </th>   <td>1.41e+06</td>   \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.41e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               E_t2_HVZ   R-squared:                       0.679\n",
       "Model:                            OLS   Adj. R-squared:                  0.678\n",
       "Method:                 Least Squares   F-statistic:                     4934.\n",
       "Date:                Sat, 06 May 2023   Prob (F-statistic):               0.00\n",
       "Time:                        20:00:41   Log-Likelihood:            -2.5364e+05\n",
       "No. Observations:               30391   AIC:                         5.073e+05\n",
       "Df Residuals:                   30377   BIC:                         5.074e+05\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "at                  -0.0138      0.001    -15.266      0.000      -0.016      -0.012\n",
       "dvc                  0.0290      0.011      2.532      0.011       0.007       0.051\n",
       "E_t                  0.4412      0.008     52.199      0.000       0.425       0.458\n",
       "dummy_Neg_E_t      -17.6157     12.378     -1.423      0.155     -41.878       6.647\n",
       "ACT                  0.2255      0.009     25.604      0.000       0.208       0.243\n",
       "div_payout_ratio     0.3111      0.648      0.480      0.631      -0.960       1.582\n",
       "total_debt           0.0498      0.002     27.028      0.000       0.046       0.053\n",
       "deq_ratio           -0.0844      0.465     -0.182      0.856      -0.995       0.826\n",
       "roa              -5.185e-05   9.62e-06     -5.390      0.000   -7.07e-05    -3.3e-05\n",
       "oancf                0.3405      0.007     48.389      0.000       0.327       0.354\n",
       "rdip                -1.1376      0.126     -9.012      0.000      -1.385      -0.890\n",
       "invch               -0.3023      0.022    -13.897      0.000      -0.345      -0.260\n",
       "sale                -0.0101      0.062     -0.164      0.870      -0.131       0.111\n",
       "intercept           32.2529      7.715      4.180      0.000      17.131      47.375\n",
       "==============================================================================\n",
       "Omnibus:                    35448.761   Durbin-Watson:                   1.961\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):        114743648.049\n",
       "Skew:                          -4.978   Prob(JB):                         0.00\n",
       "Kurtosis:                     303.857   Cond. No.                     1.41e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.41e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with infinite values\n",
    "cols_to_check_for_inf = ['at','dvc','E_t','dummy_Neg_E_t','ACT','div_payout_ratio',\n",
    "                                                 'total_debt','deq_ratio','roa','oancf','rdip','invch','sale','E_t2_HVZ']\n",
    "hvz_train_new_t2 = train_data_new[cols_to_check_for_inf].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "hvz_train_new_t2 = hvz_train_new_t2.dropna(subset=['at','dvc','E_t','dummy_Neg_E_t','ACT','div_payout_ratio',\n",
    "                                                 'total_debt','deq_ratio','roa','oancf','rdip','invch','sale','E_t2_HVZ'])\n",
    "\n",
    "\n",
    "# Estimate coefficients for HVZ Model at industry and fyear level\n",
    "hvz_model_new_t2 = ols(hvz_train_new_t2,'E_t2_HVZ',['at','dvc','E_t','dummy_Neg_E_t','ACT','div_payout_ratio',\n",
    "                                                 'total_debt','deq_ratio','roa','oancf','rdip','invch','sale'])\n",
    "params_hvz_model_new_t2 = hvz_model_new_t2.params\n",
    "hvz_model_new_t2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f2c0a73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for 2021: 339.69354764249016\n",
      "MSE for 2021: 2430544.9862655387\n",
      "RMSE for 2021: 1559.0205214382327\n",
      "Mean bias: -160.88999876956558\n",
      "Median bias: 16.451239113362583\n",
      "p-value for mean bias: 6.150709902935531e-10\n",
      "p-value for median bias: 9.413576572260152e-12\n",
      "Mean accuracy: -0.8152329365986413\n",
      "Median accuracy: 0.8236778920953923\n",
      "p-value for mean accuracy: 0.6816736493935621\n",
      "p-value for median accuracy: 0.711130353587111\n",
      "t-statistic: -6.203549993425207\n",
      "p-value for t-statistic: 6.150709902935531e-10\n"
     ]
    }
   ],
   "source": [
    "# Testing Accuracy on out of sample data\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import ttest_1samp\n",
    "# Select the same columns as used in training the model\n",
    "# Remove rows with infinite values\n",
    "hvz_test_new_t2 = test_data_new_2019[cols_to_check_for_inf+['gvkey']].replace([np.inf, -np.inf], np.nan)\n",
    "hvz_test_new_t2 = hvz_test_new_t2.dropna(subset=cols_to_check_for_inf)\n",
    "hvz_test_new_t2 = hvz_test_new_t2.set_index('gvkey')\n",
    "\n",
    "# Make predictions using the model for 2021 test data\n",
    "y_pred_2021_new = hvz_test_new_t2.apply(lambda row: params_hvz_model_new_t2['intercept'] + \\\n",
    "    params_hvz_model_new_t2['at']*row['at'] + params_hvz_model_new_t2['dvc']*row['dvc'] + \\\n",
    "    params_hvz_model_new_t2['E_t']*row['E_t'] + params_hvz_model_new_t2['dummy_Neg_E_t']*row['dummy_Neg_E_t'] + \\\n",
    "    params_hvz_model_new_t2['ACT']*row['ACT'] + params_hvz_model_new_t2['div_payout_ratio']*row['div_payout_ratio'] + \\\n",
    "    params_hvz_model_new_t2['total_debt']*row['total_debt'] + params_hvz_model_new_t2['deq_ratio']*row['deq_ratio'] + \\\n",
    "    params_hvz_model_new_t2['roa']*row['roa'] + params_hvz_model_new_t2['oancf']*row['oancf'] + \\\n",
    "    params_hvz_model_new_t2['rdip']*row['rdip'] + params_hvz_model_new_t2['invch']*row['invch'] + \\\n",
    "    params_hvz_model_new_t2['sale']*row['sale'], axis=1)\n",
    "\n",
    "\n",
    "# Reset the index of the y_pred_2020 DataFrame\n",
    "y_pred_2021_new= y_pred_2021_new.reset_index()\n",
    "y_pred_2021_new\n",
    "y_true_2021_new = test_data_new_2021[['gvkey', 'E_t']]\n",
    "merged_df = y_true_2021_new.merge(y_pred_2021_new, on='gvkey')\n",
    "# Rename the predicted column\n",
    "merged_df = merged_df.rename(columns={0: 'predicted'})\n",
    "\n",
    "# Calculate accuracy for 2021\n",
    "mae_2021 = mean_absolute_error(merged_df['E_t'], merged_df['predicted'])\n",
    "mse_2021 = mean_squared_error(merged_df['E_t'], merged_df['predicted'])\n",
    "rmse_2021 = mean_squared_error(merged_df['E_t'], merged_df['predicted'], squared=False)\n",
    "\n",
    "print(\"MAE for 2021:\", mae_2021)\n",
    "print(\"MSE for 2021:\", mse_2021)\n",
    "print(\"RMSE for 2021:\", rmse_2021)\n",
    "\n",
    "# Calculate bias and accuracy\n",
    "y_true = merged_df['E_t']\n",
    "y_pred = merged_df['predicted']\n",
    "bias = y_pred - y_true\n",
    "accuracy = 1 - abs(bias) / (y_true + 1e-9)\n",
    "\n",
    "# Compute mean and median of bias and accuracy\n",
    "bias_mean = bias.mean()\n",
    "bias_median = bias.median()\n",
    "accuracy_mean = accuracy.mean()\n",
    "accuracy_median = accuracy.median()\n",
    "from scipy.stats import ttest_rel\n",
    "# Compute p-values for mean and median bias and accuracy\n",
    "_, pval_bias_mean = ttest_1samp(bias, 0)\n",
    "_, pval_bias_median = ttest_1samp(bias, bias_median)\n",
    "_, pval_accuracy_mean = ttest_1samp(accuracy, 1)\n",
    "_, pval_accuracy_median = ttest_1samp(accuracy, accuracy_median)\n",
    "\n",
    "# Compute t-statistic\n",
    "t_statistic, p_value = ttest_rel(y_pred, y_true)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean bias: {bias_mean}\")\n",
    "print(f\"Median bias: {bias_median}\")\n",
    "print(f\"p-value for mean bias: {pval_bias_mean}\")\n",
    "print(f\"p-value for median bias: {pval_bias_median}\")\n",
    "print(f\"Mean accuracy: {accuracy_mean}\")\n",
    "print(f\"Median accuracy: {accuracy_median}\")\n",
    "print(f\"p-value for mean accuracy: {pval_accuracy_mean}\")\n",
    "print(f\"p-value for median accuracy: {pval_accuracy_median}\")\n",
    "print(f\"t-statistic: {t_statistic}\")\n",
    "print(f\"p-value for t-statistic: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1624c2",
   "metadata": {},
   "source": [
    "#### Modified Model for Year 2022 to predict for 2022 earnings with new features using RI model selected in Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c42d111d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>E_t3_EP_RI</td>    <th>  R-squared:         </th>  <td>   0.964</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.964</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>6.357e+04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 May 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:42:31</td>     <th>  Log-Likelihood:    </th> <td>-2.6872e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 33172</td>      <th>  AIC:               </th>  <td>5.375e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 33157</td>      <th>  BIC:               </th>  <td>5.376e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>at</th>                     <td>   -0.0013</td> <td>    0.001</td> <td>   -2.007</td> <td> 0.045</td> <td>   -0.003</td> <td>   -3e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dvc</th>                    <td>    0.0070</td> <td>    0.008</td> <td>    0.848</td> <td> 0.396</td> <td>   -0.009</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dummy_Neg_E_t</th>          <td>   30.4566</td> <td>    9.281</td> <td>    3.282</td> <td> 0.001</td> <td>   12.266</td> <td>   48.647</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>div_payout_ratio</th>       <td>   -0.0574</td> <td>    0.414</td> <td>   -0.139</td> <td> 0.890</td> <td>   -0.868</td> <td>    0.754</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_debt</th>             <td>    0.0016</td> <td>    0.001</td> <td>    1.149</td> <td> 0.250</td> <td>   -0.001</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>deq_ratio</th>              <td>   -0.0224</td> <td>    0.231</td> <td>   -0.097</td> <td> 0.923</td> <td>   -0.476</td> <td>    0.431</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roa</th>                    <td> 1.146e-06</td> <td> 7.46e-06</td> <td>    0.154</td> <td> 0.878</td> <td>-1.35e-05</td> <td> 1.58e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>oancf</th>                  <td>    0.0028</td> <td>    0.004</td> <td>    0.771</td> <td> 0.441</td> <td>   -0.004</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rdip</th>                   <td>   -0.0196</td> <td>    0.096</td> <td>   -0.204</td> <td> 0.839</td> <td>   -0.209</td> <td>    0.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>invch</th>                  <td>   -0.0144</td> <td>    0.016</td> <td>   -0.903</td> <td> 0.366</td> <td>   -0.046</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sale</th>                   <td>    0.0120</td> <td>    0.049</td> <td>    0.246</td> <td> 0.806</td> <td>   -0.083</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Neg_E_interaction_term</th> <td>    4.0722</td> <td>    0.006</td> <td>  652.807</td> <td> 0.000</td> <td>    4.060</td> <td>    4.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B_t</th>                    <td>  -18.2668</td> <td>    0.065</td> <td> -282.065</td> <td> 0.000</td> <td>  -18.394</td> <td>  -18.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TACC_t</th>                 <td>   22.1315</td> <td>    0.075</td> <td>  297.002</td> <td> 0.000</td> <td>   21.985</td> <td>   22.278</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>              <td>   -7.7121</td> <td>    5.719</td> <td>   -1.348</td> <td> 0.178</td> <td>  -18.922</td> <td>    3.497</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>123346.961</td> <th>  Durbin-Watson:     </th>     <td>   1.983</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>288660011917.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td>80.745</td>   <th>  Prob(JB):          </th>     <td>    0.00</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>14453.604</td> <th>  Cond. No.          </th>     <td>1.35e+06</td>    \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.35e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             E_t3_EP_RI   R-squared:                       0.964\n",
       "Model:                            OLS   Adj. R-squared:                  0.964\n",
       "Method:                 Least Squares   F-statistic:                 6.357e+04\n",
       "Date:                Sat, 06 May 2023   Prob (F-statistic):               0.00\n",
       "Time:                        23:42:31   Log-Likelihood:            -2.6872e+05\n",
       "No. Observations:               33172   AIC:                         5.375e+05\n",
       "Df Residuals:                   33157   BIC:                         5.376e+05\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "at                        -0.0013      0.001     -2.007      0.045      -0.003      -3e-05\n",
       "dvc                        0.0070      0.008      0.848      0.396      -0.009       0.023\n",
       "dummy_Neg_E_t             30.4566      9.281      3.282      0.001      12.266      48.647\n",
       "div_payout_ratio          -0.0574      0.414     -0.139      0.890      -0.868       0.754\n",
       "total_debt                 0.0016      0.001      1.149      0.250      -0.001       0.004\n",
       "deq_ratio                 -0.0224      0.231     -0.097      0.923      -0.476       0.431\n",
       "roa                     1.146e-06   7.46e-06      0.154      0.878   -1.35e-05    1.58e-05\n",
       "oancf                      0.0028      0.004      0.771      0.441      -0.004       0.010\n",
       "rdip                      -0.0196      0.096     -0.204      0.839      -0.209       0.169\n",
       "invch                     -0.0144      0.016     -0.903      0.366      -0.046       0.017\n",
       "sale                       0.0120      0.049      0.246      0.806      -0.083       0.107\n",
       "Neg_E_interaction_term     4.0722      0.006    652.807      0.000       4.060       4.084\n",
       "B_t                      -18.2668      0.065   -282.065      0.000     -18.394     -18.140\n",
       "TACC_t                    22.1315      0.075    297.002      0.000      21.985      22.278\n",
       "intercept                 -7.7121      5.719     -1.348      0.178     -18.922       3.497\n",
       "==============================================================================\n",
       "Omnibus:                   123346.961   Durbin-Watson:                   1.983\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):     288660011917.089\n",
       "Skew:                          80.745   Prob(JB):                         0.00\n",
       "Kurtosis:                   14453.604   Cond. No.                     1.35e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.35e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with infinite values\n",
    "cols_to_check_for_inf = ['dummy_Neg_E_t','Neg_E_interaction_term','B_t','TACC_t','E_t3_EP_RI','at','dvc',\n",
    "                         'div_payout_ratio','total_debt','deq_ratio','roa','oancf','rdip','invch','sale' ]\n",
    "\n",
    "ri_train_new_t3 = train_data_new[cols_to_check_for_inf].replace([np.inf, -np.inf], np.nan)\n",
    "# remove NANs \n",
    "ri_train_new_t3 = ri_train_new_t3.dropna(subset=cols_to_check_for_inf)\n",
    "\n",
    "\n",
    "# Estimate coefficients for HVZ Model at industry and fyear level\n",
    "ri_model_new_t3 = ols(ri_train_new_t3,'E_t3_EP_RI',['at','dvc','dummy_Neg_E_t','div_payout_ratio',\n",
    "                                                 'total_debt','deq_ratio','roa','oancf','rdip','invch','sale',\n",
    "                                                     'Neg_E_interaction_term','B_t','TACC_t'])\n",
    "params_ri_model_new_t3 = ri_model_new_t3.params\n",
    "ri_model_new_t3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5173d0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for 2022: 830.6032446014058\n",
      "MSE for 2022: 13953025.592651855\n",
      "RMSE for 2022: 3735.3748931870086\n",
      "Mean bias: -722.003073426322\n",
      "Median bias: -27.805979775128293\n",
      "p-value for mean bias: 2.257948183452738e-25\n",
      "p-value for median bias: 1.3075694405887213e-23\n",
      "Mean accuracy: -2.23480181811288\n",
      "Median accuracy: 0.1542689448828456\n",
      "p-value for mean accuracy: 0.3436131979315179\n",
      "p-value for median accuracy: 0.48425755185535757\n",
      "t-statistic: -10.509702000185818\n",
      "p-value for t-statistic: 2.257948183452738e-25\n"
     ]
    }
   ],
   "source": [
    "# Testing Accuracy on out of sample data\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import ttest_1samp\n",
    "# Select the same columns as used in training the model\n",
    "# Remove rows with infinite values\n",
    "ri_test_new_t3 = test_data_new_2019[cols_to_check_for_inf+['gvkey']].replace([np.inf, -np.inf], np.nan)\n",
    "ri_test_new_t3 = ri_test_new_t3.dropna(subset=cols_to_check_for_inf)\n",
    "ri_test_new_t3 = ri_test_new_t3.set_index('gvkey')\n",
    "\n",
    "# Make predictions using the model\n",
    "y_pred_new_2022 = ri_test_new_t3.apply(lambda row: params_ri_model_new_t3['intercept'] + \\\n",
    "    params_ri_model_new_t3['at']*row['at'] + \\\n",
    "    params_ri_model_new_t3['dvc']*row['dvc'] + \\\n",
    "    params_ri_model_new_t3['dummy_Neg_E_t']*row['dummy_Neg_E_t'] + \\\n",
    "    params_ri_model_new_t3['div_payout_ratio']*row['div_payout_ratio'] + \\\n",
    "    params_ri_model_new_t3['total_debt']*row['total_debt'] + \\\n",
    "    params_ri_model_new_t3['deq_ratio']*row['deq_ratio'] + \\\n",
    "    params_ri_model_new_t3['roa']*row['roa'] + \\\n",
    "    params_ri_model_new_t3['oancf']*row['oancf'] + \\\n",
    "    params_ri_model_new_t3['rdip']*row['rdip'] + \\\n",
    "    params_ri_model_new_t3['invch']*row['invch'] + \\\n",
    "    params_ri_model_new_t3['sale']*row['sale'] + \\\n",
    "    params_ri_model_new_t3['Neg_E_interaction_term']*row['Neg_E_interaction_term'] + \\\n",
    "    params_ri_model_new_t3['B_t']*row['B_t'] + \\\n",
    "    params_ri_model_new_t3['TACC_t']*row['TACC_t'], axis=1)\n",
    "\n",
    "# Reset the index of the y_pred_2022 DataFrame\n",
    "y_pred_new_2022 = y_pred_new_2022.reset_index()\n",
    "\n",
    "y_true_new_2022= test_data_new_2022[['gvkey', 'E_t']]\n",
    "merged_df = y_true_new_2022.merge(y_pred_new_2022, on='gvkey')\n",
    "\n",
    "# Rename the predicted column\n",
    "merged_df = merged_df.rename(columns={0: 'predicted'})\n",
    "\n",
    "# Calculate accuracy for 2022\n",
    "mae_new_2022 = mean_absolute_error(merged_df['E_t'], merged_df['predicted'])\n",
    "mse_new_2022 = mean_squared_error(merged_df['E_t'], merged_df['predicted'])\n",
    "rmse_new_2022 = mean_squared_error(merged_df['E_t'], merged_df['predicted'], squared=False)\n",
    "\n",
    "print(\"MAE for 2022:\", mae_new_2022)\n",
    "print(\"MSE for 2022:\", mse_new_2022)\n",
    "print(\"RMSE for 2022:\", rmse_new_2022)\n",
    "\n",
    "# Calculate bias and accuracy\n",
    "y_true = merged_df['E_t']\n",
    "y_pred = merged_df['predicted']\n",
    "bias = y_pred - y_true\n",
    "accuracy = 1 - abs(bias) / (y_true + 1e-9)\n",
    "\n",
    "# Compute mean and median of bias and accuracy\n",
    "bias_mean = bias.mean()\n",
    "bias_median = bias.median()\n",
    "accuracy_mean = accuracy.mean()\n",
    "accuracy_median = accuracy.median()\n",
    "\n",
    "# Compute p-values for mean and median bias and accuracy\n",
    "_, pval_bias_mean = ttest_1samp(bias, 0)\n",
    "_, pval_bias_median = ttest_1samp(bias, bias_median)\n",
    "_, pval_accuracy_mean = ttest_1samp(accuracy, 1)\n",
    "_, pval_accuracy_median = ttest_1samp(accuracy, accuracy_median)\n",
    "\n",
    "# Compute t-statistic\n",
    "t_statistic, p_value = ttest_rel(y_pred, y_true)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean bias: {bias_mean}\")\n",
    "print(f\"Median bias: {bias_median}\")\n",
    "print(f\"p-value for mean bias: {pval_bias_mean}\")\n",
    "print(f\"p-value for median bias: {pval_bias_median}\")\n",
    "print(f\"Mean accuracy: {accuracy_mean}\")\n",
    "print(f\"Median accuracy: {accuracy_median}\")\n",
    "print(f\"p-value for mean accuracy: {pval_accuracy_mean}\")\n",
    "print(f\"p-value for median accuracy: {pval_accuracy_median}\")\n",
    "print(f\"t-statistic: {t_statistic}\")\n",
    "print(f\"p-value for t-statistic: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264606b1",
   "metadata": {},
   "source": [
    "#### Based on the coefficients I have estimated above, I have forecasted 2020 annual earnings per share (EPS) for 10 stocks picked on the basis of: business, industry, and information environment; These forecasts are fairly accurate (comparing forecasted earnings to actual earnings). I have also compared my forecasts with analysts’ forecasts - IBES (comparing forecasted earnings to the analysts’ forecast for the period). The mean absolute error comes out to be 0.0473 and the Mean Squared Error comes out to be 0.0094."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "55e58bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>cusip</th>\n",
       "      <th>oftic</th>\n",
       "      <th>cname</th>\n",
       "      <th>statpers</th>\n",
       "      <th>measure</th>\n",
       "      <th>fiscalp</th>\n",
       "      <th>fpi</th>\n",
       "      <th>estflag</th>\n",
       "      <th>curcode</th>\n",
       "      <th>...</th>\n",
       "      <th>lowest</th>\n",
       "      <th>usfirm</th>\n",
       "      <th>fpedats</th>\n",
       "      <th>actual</th>\n",
       "      <th>actdats_act</th>\n",
       "      <th>acttims_act</th>\n",
       "      <th>anndats_act</th>\n",
       "      <th>anntims_act</th>\n",
       "      <th>curr_act</th>\n",
       "      <th>gvkey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000</td>\n",
       "      <td>87482X10</td>\n",
       "      <td>TLMR</td>\n",
       "      <td>TALMER BANCORP</td>\n",
       "      <td>2014-04-17</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>1.21</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>60887.0</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>59400.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000</td>\n",
       "      <td>87482X10</td>\n",
       "      <td>TLMR</td>\n",
       "      <td>TALMER BANCORP</td>\n",
       "      <td>2014-05-15</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>1.21</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>60887.0</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>59400.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000</td>\n",
       "      <td>87482X10</td>\n",
       "      <td>TLMR</td>\n",
       "      <td>TALMER BANCORP</td>\n",
       "      <td>2014-06-19</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>1.21</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>60887.0</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>59400.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000</td>\n",
       "      <td>87482X10</td>\n",
       "      <td>TLMR</td>\n",
       "      <td>TALMER BANCORP</td>\n",
       "      <td>2014-07-17</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>1.21</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>60887.0</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>59400.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000</td>\n",
       "      <td>87482X10</td>\n",
       "      <td>TLMR</td>\n",
       "      <td>TALMER BANCORP</td>\n",
       "      <td>2014-08-14</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014-12-31</td>\n",
       "      <td>1.21</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>60887.0</td>\n",
       "      <td>2015-01-30</td>\n",
       "      <td>59400.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718807</th>\n",
       "      <td>ZYNX</td>\n",
       "      <td>98986M10</td>\n",
       "      <td>ZYXI</td>\n",
       "      <td>ZYNEX</td>\n",
       "      <td>2022-10-20</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>29279.0</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>28800.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718808</th>\n",
       "      <td>ZYNX</td>\n",
       "      <td>98986M10</td>\n",
       "      <td>ZYXI</td>\n",
       "      <td>ZYNEX</td>\n",
       "      <td>2022-11-17</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>29279.0</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>28800.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718809</th>\n",
       "      <td>ZYNX</td>\n",
       "      <td>98986M10</td>\n",
       "      <td>ZYXI</td>\n",
       "      <td>ZYNEX</td>\n",
       "      <td>2022-12-15</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>29279.0</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>28800.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718810</th>\n",
       "      <td>ZYNX</td>\n",
       "      <td>98986M10</td>\n",
       "      <td>ZYXI</td>\n",
       "      <td>ZYNEX</td>\n",
       "      <td>2023-01-19</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>29279.0</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>28800.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718811</th>\n",
       "      <td>ZYNX</td>\n",
       "      <td>98986M10</td>\n",
       "      <td>ZYXI</td>\n",
       "      <td>ZYNEX</td>\n",
       "      <td>2023-02-16</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>29279.0</td>\n",
       "      <td>2023-03-13</td>\n",
       "      <td>28800.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>718812 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ticker     cusip oftic           cname    statpers measure fiscalp fpi  \\\n",
       "0        0000  87482X10  TLMR  TALMER BANCORP  2014-04-17     EPS     ANN   1   \n",
       "1        0000  87482X10  TLMR  TALMER BANCORP  2014-05-15     EPS     ANN   1   \n",
       "2        0000  87482X10  TLMR  TALMER BANCORP  2014-06-19     EPS     ANN   1   \n",
       "3        0000  87482X10  TLMR  TALMER BANCORP  2014-07-17     EPS     ANN   1   \n",
       "4        0000  87482X10  TLMR  TALMER BANCORP  2014-08-14     EPS     ANN   1   \n",
       "...       ...       ...   ...             ...         ...     ...     ...  ..   \n",
       "718807   ZYNX  98986M10  ZYXI           ZYNEX  2022-10-20     EPS     ANN   1   \n",
       "718808   ZYNX  98986M10  ZYXI           ZYNEX  2022-11-17     EPS     ANN   1   \n",
       "718809   ZYNX  98986M10  ZYXI           ZYNEX  2022-12-15     EPS     ANN   1   \n",
       "718810   ZYNX  98986M10  ZYXI           ZYNEX  2023-01-19     EPS     ANN   1   \n",
       "718811   ZYNX  98986M10  ZYXI           ZYNEX  2023-02-16     EPS     ANN   1   \n",
       "\n",
       "       estflag curcode  ...  lowest  usfirm     fpedats  actual  actdats_act  \\\n",
       "0            P     USD  ...    0.50     1.0  2014-12-31    1.21   2015-01-30   \n",
       "1            P     USD  ...    0.50     1.0  2014-12-31    1.21   2015-01-30   \n",
       "2            P     USD  ...    0.50     1.0  2014-12-31    1.21   2015-01-30   \n",
       "3            P     USD  ...    0.50     1.0  2014-12-31    1.21   2015-01-30   \n",
       "4            P     USD  ...    1.09     1.0  2014-12-31    1.21   2015-01-30   \n",
       "...        ...     ...  ...     ...     ...         ...     ...          ...   \n",
       "718807       P     USD  ...    0.41     1.0  2022-12-31    0.44   2023-03-13   \n",
       "718808       P     USD  ...    0.42     1.0  2022-12-31    0.44   2023-03-13   \n",
       "718809       P     USD  ...    0.42     1.0  2022-12-31    0.44   2023-03-13   \n",
       "718810       P     USD  ...    0.42     1.0  2022-12-31    0.44   2023-03-13   \n",
       "718811       P     USD  ...    0.42     1.0  2022-12-31    0.44   2023-03-13   \n",
       "\n",
       "        acttims_act  anndats_act  anntims_act  curr_act gvkey  \n",
       "0           60887.0   2015-01-30      59400.0       USD   NaN  \n",
       "1           60887.0   2015-01-30      59400.0       USD   NaN  \n",
       "2           60887.0   2015-01-30      59400.0       USD   NaN  \n",
       "3           60887.0   2015-01-30      59400.0       USD   NaN  \n",
       "4           60887.0   2015-01-30      59400.0       USD   NaN  \n",
       "...             ...          ...          ...       ...   ...  \n",
       "718807      29279.0   2023-03-13      28800.0       USD   NaN  \n",
       "718808      29279.0   2023-03-13      28800.0       USD   NaN  \n",
       "718809      29279.0   2023-03-13      28800.0       USD   NaN  \n",
       "718810      29279.0   2023-03-13      28800.0       USD   NaN  \n",
       "718811      29279.0   2023-03-13      28800.0       USD   NaN  \n",
       "\n",
       "[718812 rows x 27 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging IBES dataset with the Ticker List\n",
    "# Importing Link File\n",
    "# Set the file path\n",
    "file_path = r'C:\\Users\\abbas\\OneDrive\\Desktop\\MMA Studies\\Finance and Accounting Insights\\Group Project\\Link_File.xls'\n",
    "\n",
    "# Read the excel file\n",
    "link_df = pd.read_excel(file_path)\n",
    "\n",
    "link_df = link_df.rename(columns={'TICKER': 'oftic'})\n",
    "\n",
    "# Merge Compustat and IBES on the matched GVKEYs and TICKERs\n",
    "merged_ibes_df = ibes_data.merge(link_df ,on=['oftic'], how='left')\n",
    "\n",
    "merged_ibes_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "7690f890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        tic                          conm   gvkey\n",
      "58872  CPRX  CATALYST PHARMACEUTICALS INC  175966\n",
      "25895  CRSP        CRISPR THERAPEUTICS AG  028113\n",
      "24740  CLSD      CLEARSIDE BIOMEDICAL INC  026798\n",
      "10250  MSFT                MICROSOFT CORP  012141\n",
      "9505    WMT                   WALMART INC  011259\n",
      "4625   INTC                    INTEL CORP  006008\n",
      "4882    JNJ             JOHNSON & JOHNSON  006266\n",
      "608    AAPL                     APPLE INC  001690\n",
      "3590      F                 FORD MOTOR CO  004839\n",
      "1284     BP                        BP PLC  002410\n"
     ]
    }
   ],
   "source": [
    "# Pick 10 stocks \n",
    "# Strategy to pick 10 stocks - select firms with highest Total Assets and Return on Assets in 2019\n",
    "\n",
    "# Filter for fyear 2019\n",
    "df_win_new_2019 = df_win_new[df_win_new['fyear'] == 2019]\n",
    "\n",
    "# Sort by ROA and AT, descending\n",
    "df_win_new_2019_sorted = df_win_new_2019.sort_values(by=['sale'], ascending=False)\n",
    "\n",
    "# Remove rows with infinite values\n",
    "df_win_new_2019_sorted = df_win_new_2019_sorted.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# Get top 10 firms\n",
    "tickers = ['MSFT', 'BP', 'AAPL', 'F', 'JNJ', 'WMT', 'INTC', 'CLSD', 'CPRX', 'CRSP']\n",
    "mask = df_win_new_2019_sorted['tic'].isin(tickers)\n",
    "top_10 = df_win_new_2019_sorted[mask]\n",
    "\n",
    "# Print the results\n",
    "print(top_10[['tic', 'conm', 'gvkey']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "85d20860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>conm</th>\n",
       "      <th>predicted_earnings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gvkey</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175966</th>\n",
       "      <td>CPRX</td>\n",
       "      <td>CATALYST PHARMACEUTICALS INC</td>\n",
       "      <td>36.033368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>028113</th>\n",
       "      <td>CRSP</td>\n",
       "      <td>CRISPR THERAPEUTICS AG</td>\n",
       "      <td>52.231213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>026798</th>\n",
       "      <td>CLSD</td>\n",
       "      <td>CLEARSIDE BIOMEDICAL INC</td>\n",
       "      <td>-20.884361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>012141</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>MICROSOFT CORP</td>\n",
       "      <td>35362.660582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>011259</th>\n",
       "      <td>WMT</td>\n",
       "      <td>WALMART INC</td>\n",
       "      <td>14513.488450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006008</th>\n",
       "      <td>INTC</td>\n",
       "      <td>INTEL CORP</td>\n",
       "      <td>18867.185373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006266</th>\n",
       "      <td>JNJ</td>\n",
       "      <td>JOHNSON &amp; JOHNSON</td>\n",
       "      <td>16168.004649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001690</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>APPLE INC</td>\n",
       "      <td>50308.208812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>004839</th>\n",
       "      <td>F</td>\n",
       "      <td>FORD MOTOR CO</td>\n",
       "      <td>4863.262953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002410</th>\n",
       "      <td>BP</td>\n",
       "      <td>BP PLC</td>\n",
       "      <td>9034.374379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tic                          conm  predicted_earnings\n",
       "gvkey                                                         \n",
       "175966  CPRX  CATALYST PHARMACEUTICALS INC           36.033368\n",
       "028113  CRSP        CRISPR THERAPEUTICS AG           52.231213\n",
       "026798  CLSD      CLEARSIDE BIOMEDICAL INC          -20.884361\n",
       "012141  MSFT                MICROSOFT CORP        35362.660582\n",
       "011259   WMT                   WALMART INC        14513.488450\n",
       "006008  INTC                    INTEL CORP        18867.185373\n",
       "006266   JNJ             JOHNSON & JOHNSON        16168.004649\n",
       "001690  AAPL                     APPLE INC        50308.208812\n",
       "004839     F                 FORD MOTOR CO         4863.262953\n",
       "002410    BP                        BP PLC         9034.374379"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using E+1 modified model in Q2 to estimate/predict Earnings for 10 stocks\n",
    "# Make predictions using the model for 2020 \n",
    "top_10 = top_10.set_index('gvkey')\n",
    "y_pred_2020_top_10 = top_10.apply(lambda row: params_hvz_model_new_t1['intercept'] + \\\n",
    "    params_hvz_model_new_t1['at']*row['at'] + params_hvz_model_new_t1['dvc']*row['dvc'] + \\\n",
    "    params_hvz_model_new_t1['E_t']*row['E_t'] + params_hvz_model_new_t1['dummy_Neg_E_t']*row['dummy_Neg_E_t'] + \\\n",
    "    params_hvz_model_new_t1['ACT']*row['ACT'] + params_hvz_model_new_t1['div_payout_ratio']*row['div_payout_ratio'] + \\\n",
    "    params_hvz_model_new_t1['total_debt']*row['total_debt'] + params_hvz_model_new_t1['deq_ratio']*row['deq_ratio'] + \\\n",
    "    params_hvz_model_new_t1['roa']*row['roa'] + params_hvz_model_new_t1['oancf']*row['oancf'] + \\\n",
    "    params_hvz_model_new_t1['rdip']*row['rdip'] + params_hvz_model_new_t1['invch']*row['invch'] + \\\n",
    "    params_hvz_model_new_t1['sale']*row['sale'], axis=1)\n",
    "\n",
    "# convert the Series to a DataFrame\n",
    "y_pred_2020_top_10 =y_pred_2020_top_10.to_frame()\n",
    "# Rename the predicted column\n",
    "y_pred_2020_top_10 = y_pred_2020_top_10.rename(columns={0: 'predicted_earnings'})\n",
    "\n",
    "merged_df_top_10 = top_10.merge(y_pred_2020_top_10, on='gvkey')\n",
    "\n",
    "merged_df_top_10 = merged_df_top_10[['tic', 'conm', 'predicted_earnings']]\n",
    "merged_df_top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "7728cf2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>cusip</th>\n",
       "      <th>oftic</th>\n",
       "      <th>cname</th>\n",
       "      <th>statpers</th>\n",
       "      <th>measure</th>\n",
       "      <th>fiscalp</th>\n",
       "      <th>fpi</th>\n",
       "      <th>estflag</th>\n",
       "      <th>curcode</th>\n",
       "      <th>...</th>\n",
       "      <th>lowest</th>\n",
       "      <th>usfirm</th>\n",
       "      <th>fpedats</th>\n",
       "      <th>actual</th>\n",
       "      <th>actdats_act</th>\n",
       "      <th>acttims_act</th>\n",
       "      <th>anndats_act</th>\n",
       "      <th>anntims_act</th>\n",
       "      <th>curr_act</th>\n",
       "      <th>gvkey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>000V</td>\n",
       "      <td>28249U10</td>\n",
       "      <td>EIGR</td>\n",
       "      <td>EIGER</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.87</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>-2.3100</td>\n",
       "      <td>2021-03-09</td>\n",
       "      <td>60684.0</td>\n",
       "      <td>2021-03-09</td>\n",
       "      <td>58740.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>000Y</td>\n",
       "      <td>90400D10</td>\n",
       "      <td>RARE</td>\n",
       "      <td>ULTRAGENYX</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>-3.0700</td>\n",
       "      <td>2021-02-11</td>\n",
       "      <td>59544.0</td>\n",
       "      <td>2021-02-11</td>\n",
       "      <td>57900.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>30001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>000Z</td>\n",
       "      <td>09072V40</td>\n",
       "      <td>BIOC</td>\n",
       "      <td>BIOCEPT</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>-1.5000</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>58592.0</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>57900.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>2224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>001A</td>\n",
       "      <td>81776310</td>\n",
       "      <td>SESN</td>\n",
       "      <td>SESEN BIO</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>-3.8000</td>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>27795.0</td>\n",
       "      <td>2021-03-15</td>\n",
       "      <td>25200.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>001J</td>\n",
       "      <td>49926D10</td>\n",
       "      <td>KN</td>\n",
       "      <td>KNOWLES</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>62016.0</td>\n",
       "      <td>2021-02-04</td>\n",
       "      <td>57900.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>6387.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718347</th>\n",
       "      <td>ZUMZ</td>\n",
       "      <td>98981710</td>\n",
       "      <td>ZUMZ</td>\n",
       "      <td>ZUMIEZ</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>2021-03-11</td>\n",
       "      <td>63307.0</td>\n",
       "      <td>2021-03-11</td>\n",
       "      <td>58200.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>162988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718393</th>\n",
       "      <td>ZUO</td>\n",
       "      <td>98983V10</td>\n",
       "      <td>ZUO</td>\n",
       "      <td>ZUORA</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>-0.0900</td>\n",
       "      <td>2021-03-11</td>\n",
       "      <td>63497.0</td>\n",
       "      <td>2021-03-11</td>\n",
       "      <td>58020.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>33232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718601</th>\n",
       "      <td>ZY</td>\n",
       "      <td>87254010</td>\n",
       "      <td>TJX</td>\n",
       "      <td>TJX</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>0.3100</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>28801.0</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>27480.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>13504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718679</th>\n",
       "      <td>ZYNE</td>\n",
       "      <td>98986X10</td>\n",
       "      <td>ZYNE</td>\n",
       "      <td>ZYNERBA PHARMS</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>-1.9000</td>\n",
       "      <td>2021-03-10</td>\n",
       "      <td>24946.0</td>\n",
       "      <td>2021-03-10</td>\n",
       "      <td>24300.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>25128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718779</th>\n",
       "      <td>ZYNX</td>\n",
       "      <td>98986M10</td>\n",
       "      <td>ZYXI</td>\n",
       "      <td>ZYNEX INC</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>EPS</td>\n",
       "      <td>ANN</td>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "      <td>USD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>2021-02-25</td>\n",
       "      <td>63938.0</td>\n",
       "      <td>2021-02-25</td>\n",
       "      <td>61500.0</td>\n",
       "      <td>USD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4539 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ticker     cusip oftic           cname    statpers measure fiscalp fpi  \\\n",
       "272      000V  28249U10  EIGR           EIGER  2020-06-18     EPS     ANN   1   \n",
       "379      000Y  90400D10  RARE      ULTRAGENYX  2020-06-18     EPS     ANN   1   \n",
       "484      000Z  09072V40  BIOC         BIOCEPT  2020-06-18     EPS     ANN   1   \n",
       "679      001A  81776310  SESN       SESEN BIO  2020-06-18     EPS     ANN   1   \n",
       "834      001J  49926D10    KN         KNOWLES  2020-06-18     EPS     ANN   1   \n",
       "...       ...       ...   ...             ...         ...     ...     ...  ..   \n",
       "718347   ZUMZ  98981710  ZUMZ          ZUMIEZ  2020-06-18     EPS     ANN   1   \n",
       "718393    ZUO  98983V10   ZUO           ZUORA  2020-06-18     EPS     ANN   1   \n",
       "718601     ZY  87254010   TJX             TJX  2020-06-18     EPS     ANN   1   \n",
       "718679   ZYNE  98986X10  ZYNE  ZYNERBA PHARMS  2020-06-18     EPS     ANN   1   \n",
       "718779   ZYNX  98986M10  ZYXI       ZYNEX INC  2020-06-18     EPS     ANN   1   \n",
       "\n",
       "       estflag curcode  ...  lowest  usfirm     fpedats  actual  actdats_act  \\\n",
       "272          P     USD  ...   -2.87     1.0  2020-06-18 -2.3100   2021-03-09   \n",
       "379          P     USD  ...   -7.46     1.0  2020-06-18 -3.0700   2021-02-11   \n",
       "484          P     USD  ...   -2.70     1.0  2020-06-18 -1.5000   2021-03-29   \n",
       "679          P     USD  ...   -0.60     1.0  2020-06-18 -3.8000   2021-03-15   \n",
       "834          P     USD  ...    0.49     1.0  2020-06-18  0.6400   2021-02-04   \n",
       "...        ...     ...  ...     ...     ...         ...     ...          ...   \n",
       "718347       P     USD  ...    0.80     1.0  2020-06-18  3.0000   2021-03-11   \n",
       "718393       P     USD  ...   -0.26     1.0  2020-06-18 -0.0900   2021-03-11   \n",
       "718601       P     USD  ...   -0.47     1.0  2020-06-18  0.3100   2021-02-24   \n",
       "718679       P     USD  ...   -1.99     1.0  2020-06-18 -1.9000   2021-03-10   \n",
       "718779       P     USD  ...    0.34     1.0  2020-06-18  0.2364   2021-02-25   \n",
       "\n",
       "        acttims_act  anndats_act  anntims_act  curr_act     gvkey  \n",
       "272         60684.0   2021-03-09      58740.0       USD       NaN  \n",
       "379         59544.0   2021-02-11      57900.0       USD   30001.0  \n",
       "484         58592.0   2021-03-29      57900.0       USD    2224.0  \n",
       "679         27795.0   2021-03-15      25200.0       USD       NaN  \n",
       "834         62016.0   2021-02-04      57900.0       USD    6387.0  \n",
       "...             ...          ...          ...       ...       ...  \n",
       "718347      63307.0   2021-03-11      58200.0       USD  162988.0  \n",
       "718393      63497.0   2021-03-11      58020.0       USD   33232.0  \n",
       "718601      28801.0   2021-02-24      27480.0       USD   13504.0  \n",
       "718679      24946.0   2021-03-10      24300.0       USD   25128.0  \n",
       "718779      63938.0   2021-02-25      61500.0       USD       NaN  \n",
       "\n",
       "[4539 rows x 27 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataframe to include only the data for the year-end 2020\n",
    "merged_ibes_df['statpers'] = merged_ibes_df['statpers'].astype(str)\n",
    "df_2020 = merged_ibes_df[merged_ibes_df['statpers'].str.startswith('2020-06')]\n",
    "df_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "eed779fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>cname</th>\n",
       "      <th>medest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40118</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>APPLE</td>\n",
       "      <td>3.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127036</th>\n",
       "      <td>BP</td>\n",
       "      <td>BP</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167715</th>\n",
       "      <td>CLSD</td>\n",
       "      <td>CLEARSIDE</td>\n",
       "      <td>-0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182531</th>\n",
       "      <td>CPRX</td>\n",
       "      <td>CATALYST PHARMS</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187399</th>\n",
       "      <td>CRSP</td>\n",
       "      <td>CRISPR THERAPEUT</td>\n",
       "      <td>-4.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255928</th>\n",
       "      <td>F</td>\n",
       "      <td>FORD MOTOR</td>\n",
       "      <td>-1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352168</th>\n",
       "      <td>INTC</td>\n",
       "      <td>INTEL</td>\n",
       "      <td>4.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366173</th>\n",
       "      <td>JNJ</td>\n",
       "      <td>JOHNSON &amp; JOHNSO</td>\n",
       "      <td>7.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438326</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>MICROSOFT</td>\n",
       "      <td>5.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698170</th>\n",
       "      <td>WMT</td>\n",
       "      <td>WALMART</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tic             cname  medest\n",
       "40118   AAPL             APPLE    3.09\n",
       "127036    BP                BP    0.04\n",
       "167715  CLSD         CLEARSIDE   -0.40\n",
       "182531  CPRX   CATALYST PHARMS    0.39\n",
       "187399  CRSP  CRISPR THERAPEUT   -4.66\n",
       "255928     F        FORD MOTOR   -1.20\n",
       "352168  INTC             INTEL    4.79\n",
       "366173   JNJ  JOHNSON & JOHNSO    7.72\n",
       "438326  MSFT         MICROSOFT    5.69\n",
       "698170   WMT           WALMART    5.00"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter df_2020 to include only the tickers that are in the top_10 dataframe\n",
    "df_2020_top_10 = df_2020[df_2020['ticker'].isin(merged_df_top_10['tic'])]\n",
    "df_2020_top_10 = df_2020_top_10[['ticker','cname','medest']]\n",
    "df_2020_top_10 = df_2020_top_10.rename(columns={'ticker': 'tic'})\n",
    "df_2020_top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "78aecf01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>csho</th>\n",
       "      <th>prcc_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>16976.763</td>\n",
       "      <td>115.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>BP</td>\n",
       "      <td>3377.338</td>\n",
       "      <td>20.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5640</th>\n",
       "      <td>F</td>\n",
       "      <td>3978.695</td>\n",
       "      <td>8.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7343</th>\n",
       "      <td>INTC</td>\n",
       "      <td>4062.000</td>\n",
       "      <td>49.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7712</th>\n",
       "      <td>JNJ</td>\n",
       "      <td>2632.512</td>\n",
       "      <td>157.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15083</th>\n",
       "      <td>WMT</td>\n",
       "      <td>2821.000</td>\n",
       "      <td>140.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16396</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>7571.000</td>\n",
       "      <td>203.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50397</th>\n",
       "      <td>CLSD</td>\n",
       "      <td>51.861</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53611</th>\n",
       "      <td>CRSP</td>\n",
       "      <td>73.915</td>\n",
       "      <td>153.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126262</th>\n",
       "      <td>CPRX</td>\n",
       "      <td>103.782</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tic       csho  prcc_f\n",
       "1053    AAPL  16976.763  115.81\n",
       "2099      BP   3377.338   20.52\n",
       "5640       F   3978.695    8.79\n",
       "7343    INTC   4062.000   49.82\n",
       "7712     JNJ   2632.512  157.38\n",
       "15083    WMT   2821.000  140.49\n",
       "16396   MSFT   7571.000  203.51\n",
       "50397   CLSD     51.861    2.74\n",
       "53611   CRSP     73.915  153.11\n",
       "126262  CPRX    103.782    3.34"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataframe on fyear 2020 and the list of tickers\n",
    "df_filtered = delta_df[(delta_df['fyear']==2020) & (delta_df['tic'].isin(tickers))]\n",
    "\n",
    "# Select only the required columns\n",
    "df_filtered = df_filtered.loc[:, ['tic', 'csho', 'prcc_f']]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "d3e6c807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>csho</th>\n",
       "      <th>prcc_f</th>\n",
       "      <th>medest</th>\n",
       "      <th>conm</th>\n",
       "      <th>predicted_earnings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>16976.763</td>\n",
       "      <td>115.81</td>\n",
       "      <td>3.09</td>\n",
       "      <td>APPLE INC</td>\n",
       "      <td>50308.208812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BP</td>\n",
       "      <td>3377.338</td>\n",
       "      <td>20.52</td>\n",
       "      <td>0.04</td>\n",
       "      <td>BP PLC</td>\n",
       "      <td>9034.374379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>3978.695</td>\n",
       "      <td>8.79</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>FORD MOTOR CO</td>\n",
       "      <td>4863.262953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTC</td>\n",
       "      <td>4062.000</td>\n",
       "      <td>49.82</td>\n",
       "      <td>4.79</td>\n",
       "      <td>INTEL CORP</td>\n",
       "      <td>18867.185373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JNJ</td>\n",
       "      <td>2632.512</td>\n",
       "      <td>157.38</td>\n",
       "      <td>7.72</td>\n",
       "      <td>JOHNSON &amp; JOHNSON</td>\n",
       "      <td>16168.004649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WMT</td>\n",
       "      <td>2821.000</td>\n",
       "      <td>140.49</td>\n",
       "      <td>5.00</td>\n",
       "      <td>WALMART INC</td>\n",
       "      <td>14513.488450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>7571.000</td>\n",
       "      <td>203.51</td>\n",
       "      <td>5.69</td>\n",
       "      <td>MICROSOFT CORP</td>\n",
       "      <td>35362.660582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CLSD</td>\n",
       "      <td>51.861</td>\n",
       "      <td>2.74</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>CLEARSIDE BIOMEDICAL INC</td>\n",
       "      <td>-20.884361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CRSP</td>\n",
       "      <td>73.915</td>\n",
       "      <td>153.11</td>\n",
       "      <td>-4.66</td>\n",
       "      <td>CRISPR THERAPEUTICS AG</td>\n",
       "      <td>52.231213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CPRX</td>\n",
       "      <td>103.782</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.39</td>\n",
       "      <td>CATALYST PHARMACEUTICALS INC</td>\n",
       "      <td>36.033368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tic       csho  prcc_f  medest                          conm  \\\n",
       "0  AAPL  16976.763  115.81    3.09                     APPLE INC   \n",
       "1    BP   3377.338   20.52    0.04                        BP PLC   \n",
       "2     F   3978.695    8.79   -1.20                 FORD MOTOR CO   \n",
       "3  INTC   4062.000   49.82    4.79                    INTEL CORP   \n",
       "4   JNJ   2632.512  157.38    7.72             JOHNSON & JOHNSON   \n",
       "5   WMT   2821.000  140.49    5.00                   WALMART INC   \n",
       "6  MSFT   7571.000  203.51    5.69                MICROSOFT CORP   \n",
       "7  CLSD     51.861    2.74   -0.40      CLEARSIDE BIOMEDICAL INC   \n",
       "8  CRSP     73.915  153.11   -4.66        CRISPR THERAPEUTICS AG   \n",
       "9  CPRX    103.782    3.34    0.39  CATALYST PHARMACEUTICALS INC   \n",
       "\n",
       "   predicted_earnings  \n",
       "0        50308.208812  \n",
       "1         9034.374379  \n",
       "2         4863.262953  \n",
       "3        18867.185373  \n",
       "4        16168.004649  \n",
       "5        14513.488450  \n",
       "6        35362.660582  \n",
       "7          -20.884361  \n",
       "8           52.231213  \n",
       "9           36.033368  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardizing predicted earnings and analyst forecast to compare EPS of the 10 firms selected\n",
    "# merge the dataframes on the 'tic' column\n",
    "merged_df = pd.merge(df_filtered, df_2020_top_10, on='tic', how='outer')\n",
    "merged_df = pd.merge(merged_df, merged_df_top_10, on='tic', how='outer')\n",
    "merged_df.drop('cname', axis=1, inplace=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "1352bb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>csho</th>\n",
       "      <th>prcc_f</th>\n",
       "      <th>medest</th>\n",
       "      <th>conm</th>\n",
       "      <th>predicted_earnings</th>\n",
       "      <th>scaled_predicted_EPS</th>\n",
       "      <th>scaled_analyst_forecast</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>16976.763</td>\n",
       "      <td>115.81</td>\n",
       "      <td>3.09</td>\n",
       "      <td>APPLE INC</td>\n",
       "      <td>50308.208812</td>\n",
       "      <td>0.025588</td>\n",
       "      <td>0.026682</td>\n",
       "      <td>-0.001094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BP</td>\n",
       "      <td>3377.338</td>\n",
       "      <td>20.52</td>\n",
       "      <td>0.04</td>\n",
       "      <td>BP PLC</td>\n",
       "      <td>9034.374379</td>\n",
       "      <td>0.130361</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>0.128411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>3978.695</td>\n",
       "      <td>8.79</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>FORD MOTOR CO</td>\n",
       "      <td>4863.262953</td>\n",
       "      <td>0.139059</td>\n",
       "      <td>-0.136519</td>\n",
       "      <td>0.275577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTC</td>\n",
       "      <td>4062.000</td>\n",
       "      <td>49.82</td>\n",
       "      <td>4.79</td>\n",
       "      <td>INTEL CORP</td>\n",
       "      <td>18867.185373</td>\n",
       "      <td>0.093232</td>\n",
       "      <td>0.096146</td>\n",
       "      <td>-0.002914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JNJ</td>\n",
       "      <td>2632.512</td>\n",
       "      <td>157.38</td>\n",
       "      <td>7.72</td>\n",
       "      <td>JOHNSON &amp; JOHNSON</td>\n",
       "      <td>16168.004649</td>\n",
       "      <td>0.039024</td>\n",
       "      <td>0.049053</td>\n",
       "      <td>-0.010029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WMT</td>\n",
       "      <td>2821.000</td>\n",
       "      <td>140.49</td>\n",
       "      <td>5.00</td>\n",
       "      <td>WALMART INC</td>\n",
       "      <td>14513.488450</td>\n",
       "      <td>0.036620</td>\n",
       "      <td>0.035590</td>\n",
       "      <td>0.001031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>7571.000</td>\n",
       "      <td>203.51</td>\n",
       "      <td>5.69</td>\n",
       "      <td>MICROSOFT CORP</td>\n",
       "      <td>35362.660582</td>\n",
       "      <td>0.022951</td>\n",
       "      <td>0.027959</td>\n",
       "      <td>-0.005008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CLSD</td>\n",
       "      <td>51.861</td>\n",
       "      <td>2.74</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>CLEARSIDE BIOMEDICAL INC</td>\n",
       "      <td>-20.884361</td>\n",
       "      <td>-0.146970</td>\n",
       "      <td>-0.145985</td>\n",
       "      <td>-0.000985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CRSP</td>\n",
       "      <td>73.915</td>\n",
       "      <td>153.11</td>\n",
       "      <td>-4.66</td>\n",
       "      <td>CRISPR THERAPEUTICS AG</td>\n",
       "      <td>52.231213</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>-0.030436</td>\n",
       "      <td>0.035051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CPRX</td>\n",
       "      <td>103.782</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.39</td>\n",
       "      <td>CATALYST PHARMACEUTICALS INC</td>\n",
       "      <td>36.033368</td>\n",
       "      <td>0.103953</td>\n",
       "      <td>0.116766</td>\n",
       "      <td>-0.012814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tic       csho  prcc_f  medest                          conm  \\\n",
       "0  AAPL  16976.763  115.81    3.09                     APPLE INC   \n",
       "1    BP   3377.338   20.52    0.04                        BP PLC   \n",
       "2     F   3978.695    8.79   -1.20                 FORD MOTOR CO   \n",
       "3  INTC   4062.000   49.82    4.79                    INTEL CORP   \n",
       "4   JNJ   2632.512  157.38    7.72             JOHNSON & JOHNSON   \n",
       "5   WMT   2821.000  140.49    5.00                   WALMART INC   \n",
       "6  MSFT   7571.000  203.51    5.69                MICROSOFT CORP   \n",
       "7  CLSD     51.861    2.74   -0.40      CLEARSIDE BIOMEDICAL INC   \n",
       "8  CRSP     73.915  153.11   -4.66        CRISPR THERAPEUTICS AG   \n",
       "9  CPRX    103.782    3.34    0.39  CATALYST PHARMACEUTICALS INC   \n",
       "\n",
       "   predicted_earnings  scaled_predicted_EPS  scaled_analyst_forecast      diff  \n",
       "0        50308.208812              0.025588                 0.026682 -0.001094  \n",
       "1         9034.374379              0.130361                 0.001949  0.128411  \n",
       "2         4863.262953              0.139059                -0.136519  0.275577  \n",
       "3        18867.185373              0.093232                 0.096146 -0.002914  \n",
       "4        16168.004649              0.039024                 0.049053 -0.010029  \n",
       "5        14513.488450              0.036620                 0.035590  0.001031  \n",
       "6        35362.660582              0.022951                 0.027959 -0.005008  \n",
       "7          -20.884361             -0.146970                -0.145985 -0.000985  \n",
       "8           52.231213              0.004615                -0.030436  0.035051  \n",
       "9           36.033368              0.103953                 0.116766 -0.012814  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dividing predicted_earnings by (csho*prcc_f) and medest by prcc_f\n",
    "merged_df['scaled_predicted_EPS'] = merged_df['predicted_earnings']/(merged_df['csho']*merged_df['prcc_f'])\n",
    "merged_df['scaled_analyst_forecast'] = merged_df['medest']/merged_df['prcc_f']\n",
    "merged_df['diff'] = merged_df['scaled_predicted_EPS'] - merged_df['scaled_analyst_forecast']\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "d3d8da06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.0473\n",
      "MSE: 0.0094\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(merged_df['scaled_predicted_EPS'], merged_df['scaled_analyst_forecast'])\n",
    "mse = mean_squared_error(merged_df['scaled_predicted_EPS'], merged_df['scaled_analyst_forecast'])\n",
    "\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c314d0",
   "metadata": {},
   "source": [
    "#### Applying coefficients estimated above to 2022 data to predict the top 10 firms that are most likely to exhibit the largest earnings growth in 2023. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "3666f3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>predicted_earnings_2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001050</td>\n",
       "      <td>35.536727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001075</td>\n",
       "      <td>636.824590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001078</td>\n",
       "      <td>7038.340957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001096</td>\n",
       "      <td>234.369765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001104</td>\n",
       "      <td>15.313474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3603</th>\n",
       "      <td>345699</td>\n",
       "      <td>-135.493754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3604</th>\n",
       "      <td>345764</td>\n",
       "      <td>-5.157191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3605</th>\n",
       "      <td>345920</td>\n",
       "      <td>-67.316008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606</th>\n",
       "      <td>345980</td>\n",
       "      <td>-289.615473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3607</th>\n",
       "      <td>351590</td>\n",
       "      <td>2575.251257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3608 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gvkey  predicted_earnings_2023\n",
       "0     001050                35.536727\n",
       "1     001075               636.824590\n",
       "2     001078              7038.340957\n",
       "3     001096               234.369765\n",
       "4     001104                15.313474\n",
       "...      ...                      ...\n",
       "3603  345699              -135.493754\n",
       "3604  345764                -5.157191\n",
       "3605  345920               -67.316008\n",
       "3606  345980              -289.615473\n",
       "3607  351590              2575.251257\n",
       "\n",
       "[3608 rows x 2 columns]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying coefficients of E_t+1 model estimated in Q2 to predict earnings for 2023. \n",
    "# Note: The modified model in Q2 for E_t+1 is trained till 2018 data and is used to predict earnings for 2020.\n",
    "#       Here as the question asks, we have used this model to predict 2023 earnings using data from 2022.\n",
    "\n",
    "# Select the same columns as used in training the model\n",
    "cols_to_check_for_inf = ['at','dvc','E_t','dummy_Neg_E_t','ACT','div_payout_ratio',\n",
    "                                                 'total_debt','deq_ratio','roa','oancf','rdip','invch','sale']\n",
    "# Remove rows with infinite values\n",
    "hvz_final = test_data_new_2022[cols_to_check_for_inf+['gvkey']].replace([np.inf, -np.inf], np.nan)\n",
    "hvz_final = hvz_final.dropna(subset=cols_to_check_for_inf)\n",
    "hvz_final = hvz_final.set_index('gvkey')\n",
    "\n",
    "# Make predictions using the model for 2020 data\n",
    "y_pred_2023 = hvz_final.apply(lambda row: params_hvz_model_new_t1['intercept'] + \\\n",
    "    params_hvz_model_new_t1['at']*row['at'] + params_hvz_model_new_t1['dvc']*row['dvc'] + \\\n",
    "    params_hvz_model_new_t1['E_t']*row['E_t'] + params_hvz_model_new_t1['dummy_Neg_E_t']*row['dummy_Neg_E_t'] + \\\n",
    "    params_hvz_model_new_t1['ACT']*row['ACT'] + params_hvz_model_new_t1['div_payout_ratio']*row['div_payout_ratio'] + \\\n",
    "    params_hvz_model_new_t1['total_debt']*row['total_debt'] + params_hvz_model_new_t1['deq_ratio']*row['deq_ratio'] + \\\n",
    "    params_hvz_model_new_t1['roa']*row['roa'] + params_hvz_model_new_t1['oancf']*row['oancf'] + \\\n",
    "    params_hvz_model_new_t1['rdip']*row['rdip'] + params_hvz_model_new_t1['invch']*row['invch'] + \\\n",
    "    params_hvz_model_new_t1['sale']*row['sale'], axis=1)\n",
    "\n",
    "# Reset the index of the y_pred_2020 DataFrame\n",
    "y_pred_2023= y_pred_2023.reset_index()\n",
    "# Rename the predicted column\n",
    "y_pred_2023 = y_pred_2023.rename(columns={0: 'predicted_earnings_2023'})\n",
    "y_pred_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "7ff2d12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>earnings_growth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>016564</td>\n",
       "      <td>8877.491611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>001718</td>\n",
       "      <td>3031.387159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>175548</td>\n",
       "      <td>927.862226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>017349</td>\n",
       "      <td>337.163856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>024368</td>\n",
       "      <td>125.695625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>021563</td>\n",
       "      <td>108.650485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>060801</td>\n",
       "      <td>105.988442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2853</th>\n",
       "      <td>143788</td>\n",
       "      <td>102.290555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>001783</td>\n",
       "      <td>97.651521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>011372</td>\n",
       "      <td>80.211035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gvkey  earnings_growth\n",
       "683   016564      8877.491611\n",
       "33    001718      3031.387159\n",
       "3165  175548       927.862226\n",
       "704   017349       337.163856\n",
       "1097  024368       125.695625\n",
       "961   021563       108.650485\n",
       "2345  060801       105.988442\n",
       "2853  143788       102.290555\n",
       "37    001783        97.651521\n",
       "493   011372        80.211035"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating Earnings Growth using year 2022 earnings and predicted earnings for 2023 \n",
    "growth_df = pd.merge(y_pred_2023, test_data_new_2022[['gvkey','E_t']], on='gvkey', how='left')\n",
    "\n",
    "\n",
    "growth_df['earnings_growth'] = (growth_df['predicted_earnings_2023'] - growth_df['E_t']) / growth_df['E_t']\n",
    "top_10_earnings_growth = growth_df[['gvkey', 'earnings_growth']].sort_values('earnings_growth', ascending=False).head(10)\n",
    "top_10_earnings_growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "ec3419d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>earnings_growth</th>\n",
       "      <th>conm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>016564</td>\n",
       "      <td>8877.491611</td>\n",
       "      <td>WALL STREET MEDIA CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001718</td>\n",
       "      <td>3031.387159</td>\n",
       "      <td>ADVANCED OXYGEN TECHNOLOGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175548</td>\n",
       "      <td>927.862226</td>\n",
       "      <td>NEXGENRX INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>017349</td>\n",
       "      <td>337.163856</td>\n",
       "      <td>SKKYNET CLOUD SYSTEMS INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>024368</td>\n",
       "      <td>125.695625</td>\n",
       "      <td>RETAIL HOLDINGS NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>021563</td>\n",
       "      <td>108.650485</td>\n",
       "      <td>ELECTRONIC SYSTEM TECH INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>060801</td>\n",
       "      <td>105.988442</td>\n",
       "      <td>SOCKET MOBILE INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>143788</td>\n",
       "      <td>102.290555</td>\n",
       "      <td>REFLECT SCIENTIFIC INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>001783</td>\n",
       "      <td>97.651521</td>\n",
       "      <td>ARTS WAY MFG INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>011372</td>\n",
       "      <td>80.211035</td>\n",
       "      <td>NEW CONCEPT ENERGY INC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gvkey  earnings_growth                        conm\n",
       "0  016564      8877.491611        WALL STREET MEDIA CO\n",
       "1  001718      3031.387159  ADVANCED OXYGEN TECHNOLOGY\n",
       "2  175548       927.862226                NEXGENRX INC\n",
       "3  017349       337.163856   SKKYNET CLOUD SYSTEMS INC\n",
       "4  024368       125.695625          RETAIL HOLDINGS NV\n",
       "5  021563       108.650485  ELECTRONIC SYSTEM TECH INC\n",
       "6  060801       105.988442           SOCKET MOBILE INC\n",
       "7  143788       102.290555      REFLECT SCIENTIFIC INC\n",
       "8  001783        97.651521            ARTS WAY MFG INC\n",
       "9  011372        80.211035      NEW CONCEPT ENERGY INC"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get company names for these gvkeys\n",
    "top_10_firms_final = pd.merge(top_10_earnings_growth, test_data_new_2022[['gvkey', 'conm']], on='gvkey', how='left')\n",
    "top_10_firms_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6690cd1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
